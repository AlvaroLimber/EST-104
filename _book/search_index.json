[["index.html", "Estadística EST-104 Prefacio Audiencia Estructura del libro Software y acuerdos Bases de datos Agradecimiento", " Estadística EST-104 MSc. Alvaro Chirino Gutierrez 2022-05-29 Prefacio Este documento de Alvaro Chirino esta bajo la licencia de Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Audiencia El libro fue diseñado originalmente para los estudiantes de la materia de Estadística, una materia del pregrado de la carrera de Biología de la Universidad Mayor de San Ándres. Estructura del libro El libro incluye 4 capítulos, estos son: Estadística descriptiva Probabilidad y distribuciones teóricas Muestreo Distribución bivariante, regresión Software y acuerdos sessionInfo() ## R version 4.1.3 (2022-03-10) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 19044) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils ## [5] datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.25 digest_0.6.29 ## [3] R6_2.5.1 jsonlite_1.8.0 ## [5] magrittr_2.0.2 evaluate_0.15 ## [7] highr_0.9 stringi_1.7.6 ## [9] rlang_1.0.2 cli_3.2.0 ## [11] rstudioapi_0.13 jquerylib_0.1.4 ## [13] bslib_0.3.1 rmarkdown_2.13 ## [15] tools_4.1.3 stringr_1.4.0 ## [17] xfun_0.30 yaml_2.3.5 ## [19] fastmap_1.1.0 compiler_4.1.3 ## [21] htmltools_0.5.2 knitr_1.38 ## [23] sass_0.4.1 Bases de datos En este documento se emplearan las siguientes bases de datos En construcción Estas bases de datos se encuentran disponibles en formato \\(.RData\\) en el repositorio de Github del texto. Agradecimiento En construcción "],["tema-1-estadística-descriptiva.html", "1 Tema 1: Estadística Descriptiva 1.1 Definición de la estadística. 1.2 Historia 1.3 Conceptos importantes 1.4 Tipos de variables 1.5 Ordenando los datos 1.6 Frecuencias absolutas, relativas y porcentajes 1.7 Medidas de tendencia central 1.8 Medidas de tendencia central para tablas de frecuencias 1.9 Medidas de variabilidad 1.10 Medidas de forma", " 1 Tema 1: Estadística Descriptiva 1.1 Definición de la estadística. El arte de contar una historia con datos La información, los datos, son la fuente primaria para la estadística. La estadística cubre los métodos, técnicas detrás de: Recolección de información Procesar la información (limpieza, depuración, coherencia, etc.) Análisis de la información Visualización de la información Es una ciencia transversal La estadística es la gramática de las ciencia La ciencia de datos en el nombre sexy de la estadística 1.2 Historia Censo. En la antigüedad se listaba de forma completa una determinada población, con el fin de conocer sus características. (Estadística descriptiva) Censos de población y vivienda (2012, 2001, 1992, 1976, etc.) Censos de Agropecuario (2013, 1984) Censos económicos, unidades económicas de un país o región. Muestra e inferencia. El objetivo de esta fase es explicar lo que le sucede a una población a partir de una muestra de ella. (Probabilidad, variables aleatorias). Explosión de conocimiento. Nace a partir de la aparición del ordenador. Minería de datos, minería de texto, machine learning, ciencia de datos, big data, etc. 1.2.1 Tarea de repaso. Buscar los conceptos de: Machine learning Minería de datos Minería de texto Estadística multivariante Buscar que tipo de bases de datos se utilizan en la biología en general y en Bolivia. 1.3 Conceptos importantes 1.3.1 Población Una colección de objetos/elementos, por ejemplo; personas, cosas, animales, etc. Sea la población o universo de estudio identificado como \\(U\\). Debemos distinguir entre las poblaciones finitas y poblaciones infinitas, en este capítulo se trabaja sobre universos finitos. \\[U=\\{u_1, u_2, \\ldots ,u_i,\\ldots, u_N \\}\\] Vamos a utilizar la letra \\(N\\) para referirnos al tamaño del universo. 1.3.2 Muestra Es un sub conjunto del universo, lo vamos a denotar con \\(s\\). \\(s \\subset U\\). \\[s=\\{u_{(1)}, u_{(2)}, \\ldots, u_{(n)} \\}\\] Donde \\(u_{(i)} \\in U\\). Nota: El tamaño del universo o la población sera denotado por \\(N\\), y \\(n\\) al tamaño de la muestra. 1.3.3 Variable Una variable en estadística expresa una característica asociado a algún elemento en la población. Normalmente esta se la denota con \\(X\\) e \\(Y\\). (\\(X\\)) Edad (\\(Y\\)) Sexo (\\(Z\\)) Horas de sueño la pasada noche (\\(W\\)) El color de los ojos (\\(V\\)) El número de celular Las variables asociadas a un elemento en la población, la podemos denotar de la siguiente forma: \\[u_i=\\{X_{i1}, X_{i2},\\ldots, X_{ip} \\}\\] Ejercicio: Definan una población de estudio con sus elementos y listen las variables asociadas a esos elementos \\(U:\\) Vegetales verdes \\(U=\\{Lechuga, espinaca, brocoli, etc\\}\\) Peso,  Población de estudio: personas en sala de meet de estadística Unidad/elemento: Personas {Naya, Wara, Vania, etc} Variables: tienen o no foto de perfil,está su rostro o no, nombre 1.4 Tipos de variables Cualitativas Cuantitativas 1.4.1 Cualitativos (cualidades) No se pueden realizar operaciones algebraicas sobre este tipo de variables. Estas tienen una sub clasificación: Nominales: Las categorías de la variable no tienen un orden de jerarquía (el orden no importa) Ordinales: Las categorías de la variable tienen un orden de jerarquía (el orden importa) Ejercicio De un ejemplo de una variable nominal y una ordinal Variable nominal= Color de piel. Variable ordinal= Grado de escolaridad. Nominal= Colores; rojo, amarillo Ordinal= Dolor; Leve, moderado Variables nominales : nacionalidad , boliviana , argentino , brasileño , ecuatoriano  Variable ordinal medallas , oro , plata , bronce 1.4.2 Cuantitativos (cantidad) Se pueden realizar operaciones algebraicas de utilidad. Estas se dividen en 3. Discretas: Numerables (unidad de medida), ejemplos; edad en años, precio de un televisor en Bs., peso en kilogramos, la altura en cm, la cantidad de personas es un evento. Continuas: No numerables; edad de una persona, cualquier variables definida en los números reales. (Volumen, distancia, tiempo) Intervalos: Variables que se describen como un rango de números. Por ejemplo; Rangos de edad 0-15, 16-49, 50+, tiempo en horas de un día; 0 a 8:00, 8:01 a 15:00, 15+ Nota: Las variables continuas se pueden volver variables discretas (discretizar una variable) Tarea: Definición y diferencia de precisión y exactitud. 1.5 Ordenando los datos La idea de este punto es conocer las formas en las que se puede manejar las información disponible. Podemos observar tres formas de ordenar la información proveniente de una sola variable. Mantenerlos en su forma simple (Datos no ordenados, datos simples). Tenerlos en una tabla de frecuencias, es una tabla que para cada valor de la variable se realiza un proceso de conteo. Tener los datos en una tabla de frecuencias con intervalos de clase. bd&lt;-read.csv(&quot;bd.csv&quot;) #simple bd$Edad ## [1] 19 18 18 21 23 18 18 19 20 28 18 21 21 18 ## [15] 18 18 17 31 17 17 20 21 19 19 22 18 22 17 ## [29] 17 19 20 17 20 20 20 19 bd$Sexo ## [1] &quot;Hombre&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Hombre&quot; ## [5] &quot;Hombre&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; ## [9] &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Hombre&quot; ## [13] &quot;Hombre&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; ## [17] &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; ## [21] &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; ## [25] &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; ## [29] &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Hombre&quot; ## [33] &quot;Mujer&quot; &quot;Mujer&quot; &quot;Mujer&quot; &quot;Hombre&quot; #frecuencia simples table(bd$Edad) ## ## 17 18 19 20 21 22 23 28 31 ## 6 9 6 6 4 2 1 1 1 table(bd$Sexo) ## ## Hombre Mujer ## 11 25 #frecuencias por intervalos #Edad f #17-19 21 #20-22 12 #23-31 3 1.6 Frecuencias absolutas, relativas y porcentajes La frecuencia absoluta se refiere al conteo en las unidades de medida correspondiente, se denota por: \\[f_i\\] Estas cumplen: \\[\\sum_{i=1}^k f_i=N \\quad; \\text{En } U\\] \\[\\sum_{i=1}^k f_i=n \\quad \\text{En } s\\] La frecuencia relativa se define como: \\[r_i=\\frac{f_i}{N} \\quad; \\text{en } U\\] \\[r_i=\\frac{f_i}{n} \\quad; \\text{en } s\\] Como propiedad: \\[\\sum_{i=1}^k r_i=\\sum_{i=1}^k \\frac{f_i}{N}=\\frac{1}{N}\\sum_{i=1}^k f_i=\\frac{N}{N}=1\\] El porcentaje de una frecuencia relativa se define como: \\[\\%(i)=r_i\\%= r_i*100\\] 1.7 Medidas de tendencia central Imaginemos que tenemos los siguientes números: 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 19 19 19 19 19 19 20 20 20 20 20 20 21 21 21 21 22 22 23 28 31 1.7.1 Moda (Mo) La moda es el número que aparece con mas frecuencia en la serie de datos. En los números descritos la moda es \\(Mo=18\\). Si la serie de números es: 1 1 1 2 3 3 3 . ¿Cuál es la moda?, en este caso se tienen 2 modas, el 1 y 3 (bi-modal). Nota: Si todos los números aparecen la misma cantidad de veces, no hay moda 1.7.2 Mediana (Me) La mediana corresponde al valor que se encuentra en el centro, de la serie de números ordenados. Es el número que deja la misma cantidad de información tanto a la derecha como a la izquierda. Imagine los siguientes datos: 1 1 2 2 3 4 4 5 5 \\(Me=3\\) \\(N=9\\) \\(X_{4+1}=X_5\\) 1 1 2 2 3 4 5 5 6 6 \\(Me=3.5\\) Para obtener el valor de la mediana se debe tomar el cuenta si la cantidad de datos es impar o par. Si \\(N\\) es impar: \\[Me= X_{||N/2||+1}\\] \\[Me= X_{(N+1)/2}\\] Ejemplo 2, 2, 4, 5, 6, 8, 9. Corresponden a este conjunto (\\(X_1,X_2,X_3,X_4,X_5,X_6,X_7\\)). Entonces: \\[Me=X_{||N/2||+1}=X_{||7/2||+1}=X_{||3.5||+1}=X_{3+1}=X_4=5\\] \\[Me= X_{(N+1)/2}=X_{(7+1)/2}=X_4=5\\] Si \\(N\\) es par: \\[Me=\\frac{X_{N/2}+X_{N/2+1}}{2}\\] Ejemplo 1 1 2 2 3 4 5 5 6 6, \\(N=10\\) \\[Me=\\frac{X_{N/2}+X_{N/2+1}}{2}=\\frac{X_5+X_6}{2}=\\frac{3+4}{2}=3.5\\] Una característica positiva de la mediana es que no le afecta demasiado los valores atípicos Ejemplo Imagine que se tiene el dato de 10 personas reunidas, con las edades: 17 17 18 18 18 19 19 19 20 80 \\[Me=18.5\\] Una desventaja de la mediana es que no participan todos los datos en su calculo. 1.7.3 Media, Promedio, Media aritmética Esta medida se caracteriza en que su construcción depende de todas las observaciones en los datos, (democrática). \\[\\bar{x}=\\frac{\\sum_{i=1}^N {x_i}}{N}=\\frac{x_1+x_2+\\ldots+x_N}{N}=\\frac{x_1}{N}+\\frac{x_2}{N}+\\ldots+\\frac{x_N}{N}\\] Ejemplo, A: 3 3 3 3 3 3 3 3 3 3 \\(\\bar{x}=3 \\quad Me=3 \\quad Mo=3\\) B: 9 9 8 8 7 7 6 6 5 5 2 2 \\(\\bar{x}=74/12=6.17 \\quad Me=6.5 \\quad Mo=NoExiste\\) C: 100 99 50 1 3 \\(\\bar{x}=253/5=50.6 \\quad Me=50 \\quad Mo=NoExiste\\) Nota: La media es una medida sensible a los números atípicos. (Grandes) Ejemplo Sean los números: 2 2 3 3 4 4 5 900, encontrar la media: \\[\\bar{x}=\\frac{923}{8}=115.38\\] \\[Me=3.5\\] De ahora en adelante vamos a distinguir la media de una población de la media de una muestra. \\[\\mu_x=\\frac{\\sum_{i=1}^N x_i}{N}\\] Esta se conoce como la media poblacional, y \\[\\bar{x}=\\frac{\\sum_{i=1}^n x_i}{n}\\] Es la media de la muestral o la media muestral. De ahora en adelante vamos a suponer que trabajamos sobre muestras. 1.7.4 Media geométrica \\[\\bar{X}_G=\\sqrt[n]{x_1x_2\\ldots x_n}=\\sqrt[n]{\\prod_{i=1}^n x_i}\\] Es recomendable cuando se trabaja con razones (ratio). Ejemplo, Calcule la media geométrica para la razón de cambio de la población por década de los siguientes datos. t1&lt;-data.frame(dec=0:5,pob=c(1000,1100,1400,1450,1600,1700)) #razón de cambio x&lt;-t1$pob[-1]/t1$pob[-6] #media geométrica prod(x)^(1/5) ## [1] 1.111962 1.7.5 Media armónica \\[\\bar{X}_H=\\frac{1}{\\frac{1}{n}\\sum_{i=1}^n \\frac{1}{x_i}}=\\frac{n}{\\sum_{i=1}^n \\frac{1}{x_i}}\\] Es recomendable cuando se trabaja con distancias, velocidades Ejemplo Se tiene la información de 3 autos que recorrieron la misma ruta con las siguientes velocidades: 40km/h, 30km/h y 55km/h (la ruta tiene una distancia de 20km) x&lt;-c(40,30,55) #promedio sum(x)/3 ## [1] 41.66667 #armónica 3/sum(1/x) ## [1] 39.20792 Nota: existe una relación entre el media aritmética, la geométrica y la armónica. (si los datos son positivos y distintos) \\[\\bar{X}_H&lt;\\bar{X}_G&lt;\\bar{X}\\] 1.8 Medidas de tendencia central para tablas de frecuencias Ejemplo Para los siguientes 80 datos. library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union set.seed(999) x&lt;-round(runif(80,15,35),0) t1&lt;-data.frame(x) t1&lt;-t1 %&gt;% group_by(x) %&gt;% count(name=&quot;fi&quot;) Calcule, la moda, la mediana y el promedio. Para el promedio: \\[\\bar{X}=\\frac{\\sum_{i=1}^k x_i*f_i}{n}\\] Para la moda se debe buscar la frecuencia absoluta más alta y el valor de \\(x\\) asociada a esa frecuencia es la moda. Es posible tener más de una moda. Para la mediana, se inicia calculando la frecuencia absoluta acumulada \\(F_i\\). \\[F_i=\\sum_{j=1}^{j=i} f_j\\] Luego se sigue el criterio de \\(n\\) par o impar, y se busca la posición como el valor más cercano por arriba dentro de las frecuencias absolutas acumuladas. Ejemplo, para la tabla anterior sum(t1$x*t1$fi)/80#promedio ## [1] 24.9125 Es bi-modal en los números 31 y 32 t1$Fi&lt;-cumsum(t1$fi) Las posiciones son 40 y 41 ya que n es par, se busca estos valores en \\(Fi\\), y se encuentra que la mediana es 26, ya que la \\(F_{12}=45\\) \\(x_{12}=26\\). \\[Me=\\frac{X_{40}+X_{41}}{2}=\\frac{26+26}{2}=26\\] ## Medidas de tendencia central para tablas de frecuencias por intervalo Para una tabla con intervalos, se tiene como elementos nuevos los limites inferiores y superiores de los intervalos: t2&lt;-data.frame(lils=cut(x,5,include.lowest = T,right = F)) t2 %&gt;% group_by(lils) %&gt;% count(name=&quot;fi&quot;) ## # A tibble: 5 x 2 ## # Groups: lils [5] ## lils fi ## &lt;fct&gt; &lt;int&gt; ## 1 [15,19) 17 ## 2 [19,23) 12 ## 3 [23,27) 16 ## 4 [27,31) 15 ## 5 [31,35] 20 Para calcular la media en este tipo de tablas, primero se debe obtener al representante de clase/intervalo, de la siguiente forma: \\[x_i=\\frac{LS_i+LI_i}{2}\\] Teniendo al representante de clase se procede de forma similar a las tablas de frecuencia. \\[\\bar{X}=\\frac{\\sum_{i=1}^k x_i*f_i}{n}\\] Para la moda se tiene identificado lo que vamos a denominar un intervalo modal, este corresponde al intervalo que tiene la frecuencia absoluta más alta \\(Max(f_{i})\\), el representante de clase de este intervalo modal puede ser tomado como la moda. Para la mediana se deben seguir 2 pasos: Encontrar la clase que contiene a la mediana, para ello se calcula \\(n/2\\), esta clase se encuentra en la \\(F\\) más cercana al valor calculado. Usando la información de la clase que contiene la mediana, se calcula: \\[Me=LI_{med}+\\left(\\frac{0.5*n-F_{med-1}}{f_{med}}\\right)*(LS_{med}-LI_{med})\\] \\[Me=23+\\left(\\frac{40-29}{16}\\right)*4=23+\\frac{11*4}{16}=25.75\\] Del ejemplo de excel \\[Me=10+\\left(\\frac{52.5-15}{60}\\right)*10=16.25\\] 1.9 Medidas de variabilidad 5 5 5 5 5 5 5: Media es 5, la moda es 5 y la mediana es 5 3 3 4 5 6 7 7: Media es 5, la moda es 3, 7 y la mediana es 5 1 1 2 5 8 9 9: Media es 5, la moda es 1, 9 y la mediana es 5 Son medidas que nos indican el nivel de variabilidad o dispersión en el conjunto de datos, la mayoría de las medidas nos reflejan la concentración al rededor de la media. 1.9.1 Rango \\[R=X_{max}-X_{min}\\] Esta medida calcula la distancia entre el valor más grande y el valor más pequeño del conjunto de datos. 1.9.2 Desviación Media \\[DM=\\frac{\\sum_s |x_i-\\bar{x}|}{n}; \\quad DM=\\frac{\\sum_{i=1}^{k} |x_i-\\bar{x}|*f_i}{n}\\] Esta medida devuelve el promedio de las distancias de los datos a su promedio. Ejemplo: 5 5 5 5 5 5 5: \\(DM=0\\) 3 3 4 5 6 7 7: \\(DM=1.43\\) 1 1 2 5 8 9 9: \\(DM=3.14\\) #grupo 1 x&lt;-c(5,5,5,5,5,5,5) sum(abs(x-mean(x)))/7 ## [1] 0 #grupo 2 x&lt;-c(3,3,4,5,6,7,7) x-mean(x)#distancias ## [1] -2 -2 -1 0 1 2 2 abs(x-mean(x))#valor absoluto ## [1] 2 2 1 0 1 2 2 sum(abs(x-mean(x)))/7 ## [1] 1.428571 #grupo 3 x&lt;-c(1,1,2,5,8,9,9) x-mean(x)#distancias ## [1] -4 -4 -3 0 3 4 4 abs(x-mean(x))#valor absoluto ## [1] 4 4 3 0 3 4 4 sum(abs(x-mean(x)))/7 ## [1] 3.142857 1.9.3 Varianza La varianza es la medida más usual en la estadística, esta medida en si misma no tiene interpretación pero se la utiliza para obtener otras medias como la desviación estándar y el coeficiente de variación que si tienen una interpretación. Varianza poblacional (N) \\[V(x)=\\sigma^2=\\frac{\\sum_U (x_i-\\bar{x})^2}{N}\\] Varianza muestral (n) \\[v(x)=s^2=\\frac{\\sum_s (x_i-\\bar{x})^2}{n-1}\\] 5 5 5 5 5 5 5: \\(s^2=0\\) 3 3 4 5 6 7 7: \\(s^2=3\\) 1 1 2 5 8 9 9: \\(s^2=13.67\\) #grupo 2 x&lt;-c(3,3,4,5,6,7,7) x-mean(x)#distancias ## [1] -2 -2 -1 0 1 2 2 (x-mean(x))^2#distancias al cuadrado ## [1] 4 4 1 0 1 4 4 sum((x-mean(x))^2)#numerador ## [1] 18 sum((x-mean(x))^2)/(7-1) ## [1] 3 #grupo 3 x&lt;-c(1,1,2,5,8,9,9) x-mean(x)#distancias ## [1] -4 -4 -3 0 3 4 4 (x-mean(x))^2#distancias al cuadrado ## [1] 16 16 9 0 9 16 16 sum((x-mean(x))^2)#numerador ## [1] 82 sum((x-mean(x))^2)/(7-1) ## [1] 13.66667 Formula corta para la varianza muestral \\[v(x)=s^2=\\frac{\\sum_s x_i^2-n \\bar{x}^2}{n-1}\\] x^2 ## [1] 1 1 4 25 64 81 81 sum(x^2) ## [1] 257 sum(x^2)-7*mean(x)^2#numerador ## [1] 82 (sum(x^2)-7*mean(x)^2)/(7-1) ## [1] 13.66667 1.9.4 Desviación estándar Desviación estándar poblacional \\[\\sigma=\\sqrt{\\sigma^2}\\] Desviación estándar muestral \\[s=\\sqrt{s^2}\\] Esta medida ya se puede interpretar a diferencia de la varianza ya que la unidad de medida ya no se encuentra elevada al cuadrado. El valor obtenido normalmente es cercano a la desviación media. Ejemplo 5 5 5 5 5 5 5: \\(s=0\\) 3 3 4 5 6 7 7: \\(s=1.73\\) 1 1 2 5 8 9 9: \\(s=3.70\\) 1.9.5 Coeficiente de variación \\[cv=\\frac{s}{\\bar{x}}; \\quad cv\\%=\\frac{s}{\\bar{x}}*100\\] Es la única medida de variabilidad relativa (carece de unidad de medida). Se puede interpretar como el porcentaje en los datos que no se sienten representados por la media. Ejemplo 5 5 5 5 5 5 5: \\(cv=0/5=0\\) 3 3 4 5 6 7 7: \\(cv=1.73/5=0.346\\rightarrow 34.6\\%\\) 1 1 2 5 8 9 9: \\(cv=3.70/5=0.74\\rightarrow 74\\%\\) 1.9.6 Rango intercuartílico (boxplot) Se tiene los siguientes 100 datos de una población de personas respecto su peso. set.seed(111) x&lt;-round(rnorm(100,50,5),1) x ## [1] 51.2 48.3 48.4 38.5 49.1 50.7 42.5 44.9 ## [9] 45.3 47.5 49.1 48.0 59.2 52.0 54.0 42.2 ## [17] 49.6 48.2 44.0 51.8 51.8 51.7 50.9 49.2 ## [25] 51.6 53.0 40.8 63.6 51.0 43.5 34.4 45.3 ## [33] 57.0 41.9 38.7 55.8 49.4 51.7 46.9 43.5 ## [41] 44.1 44.4 43.2 52.4 53.7 50.1 51.7 53.2 ## [49] 62.4 59.8 51.0 57.8 54.6 51.8 50.9 45.8 ## [57] 54.9 59.0 50.6 49.4 48.9 57.2 52.0 54.6 ## [65] 57.2 48.1 51.0 46.0 51.5 57.0 55.1 52.4 ## [73] 46.6 50.8 48.1 54.7 46.8 49.5 55.2 51.9 ## [81] 43.7 46.1 52.1 48.1 43.9 55.1 52.2 43.8 ## [89] 47.0 53.3 60.3 52.5 41.3 53.6 50.1 43.0 ## [97] 56.3 49.4 46.4 43.9 set.seed(111) y&lt;-round(rnorm(100,50,1),1) z&lt;-round(rnorm(100,50,15),1) hist(x) abline(v=median(x),col=&quot;red&quot;,lwd=2) boxplot(x) par(mfrow=c(1,3)) boxplot(x,ylim=c(30,65)) boxplot(y,ylim=c(30,65)) boxplot(z,ylim=c(30,65)) dev.off() ## null device ## 1 1.9.7 Índice de diversidad Este se utiliza para variables cualitativas a diferencia de todas las medidas de variabilidad vistas anteriormente. Este índice nos ayuda a medir la homogeneidad y heterogeneidad de las categorías observadas en nuestra variable cualitativa. \\[H&#39;=\\frac{n log (n)-\\sum_{i=1}^k f_i log(f_i)}{n}\\] \\[H&#39;_{max}= log(k)\\] \\[J&#39;=\\frac{H&#39;}{H&#39;_{max}}\\] \\(J&#39;\\) es una medida de homogeneidad: \\[0\\leq J&#39;\\leq 1\\] \\(J&#39; \\rightarrow 1\\) Alta homogeneidad \\(J&#39; \\rightarrow 0\\) Alta heterogeneidad Ejemplo Tenemos los datos de una muestra de 20 gorriones y sus sitios de nidos. nidos&lt;-c(&quot;vides&quot;,&quot;alero&quot;,&quot;ramas&quot;,&quot;cueva&quot;) f&lt;-c(5,5,5,5) t1&lt;-data.frame(nidos,fi=f) t1 ## nidos fi ## 1 vides 5 ## 2 alero 5 ## 3 ramas 5 ## 4 cueva 5 \\[H&#39;=\\frac{20 log (20)-(5log(5)+5log(5)+5log(5)+5log(5))}{20}\\] \\[H&#39;=0.60206\\] \\[H&#39;_{max}=log(k)=log(4)=0.60206\\] \\[J&#39;=\\frac{H&#39;}{H&#39;_{max}}=\\frac{0.60206}{0.60206}=1\\] Ejercicios Para las siguientes 2 muestras de gorriones calcule el índice de diversidad \\(J&#39;\\) f&lt;-c(1,1,2,16) t2&lt;-data.frame(nidos,fi=f) f&lt;-c(4,4,4,8) t3&lt;-data.frame(nidos,fi=f) t2 ## nidos fi ## 1 vides 1 ## 2 alero 1 ## 3 ramas 2 ## 4 cueva 16 t3 ## nidos fi ## 1 vides 4 ## 2 alero 4 ## 3 ramas 4 ## 4 cueva 8 Para t2 \\[J&#39;=0.51\\] Para t3 \\[J&#39;=0.96\\] Nota: - Si \\(J&#39;&gt;0.9\\) Alta homogenidad - Si \\(J&#39;&lt;0.6\\) Heterogeneidad - Si \\(J&#39;&lt;0.5\\) Alta Heterogeneidad 1.10 Medidas de forma 1.10.1 Asimetría \\[As_{Fisher}=\\frac{\\mu_3}{s^3}\\] \\[\\mu_3=\\frac{\\sum_s (x_i-\\bar{x})^3}{n}\\] 1.10.2 Kurtosis \\[k=\\frac{\\mu_4}{s^4}\\] \\[\\mu_4=\\frac{\\sum_s (x_i-\\bar{x})^4}{n}\\] 1.10.3 Cuantiles quantile(x,0.99) ## 99% ## 62.412 quantile(x,0.70) ## 70% ## 52.13 Tarea: Del libro guía del capítulo de probabilidades leer los puntos 1, 2 y 3. "],["probabilidad-y-distribuciones-de-variables-aleatorias.html", "2 Probabilidad y distribuciones de variables aleatorias 2.1 Conceptos 2.2 Definición de probabilidad 2.3 Propiedades de las probabilidades 2.4 Independencia en eventos 2.5 Probabilidad condicional 2.6 Variable aleatoria", " 2 Probabilidad y distribuciones de variables aleatorias ¿Qué es la probabilidad? Es el estudio de la incertidumbre ¿Desde cuándo se empieza a hablar de probabilidad? ¿Para qué sirve? Predicciones, 2.1 Conceptos 2.1.1 Experimento aleatorio Es un proceso en el cual no se conoce previamente su resultado Ejemplos: Lanzar un dado, dos dados, 5 dados Lanzar una moneda Jugar a la loteria Una apuesta, cartas Notas del primer parcial, las notas de una materia. ¿Cuál es la probabilidad de aprobar una materia? Tiempo que van a dormir la noche del sabado 19 de marzo El sexo, número de crías en un nacimiento, el tiempo de vida de un animal 2.1.2 Espacio muestral \\[\\Omega\\] Es un conjunto que agrupa todos los resultados posibles de un experimento aleatorio Ejemplos \\(\\Omega=\\{1,2,3,4,5,6\\}\\), \\(\\Omega=\\{(1,1),(1,2),\\ldots,(6,6)\\}\\) \\(\\Omega=\\{C,S\\}\\), Lanzar un dado y una moneda \\(\\Omega=\\{(1,C),(1,S),(2,C),(2,S),\\ldots,(6,S)\\}\\) Tiempo de vida \\(\\Omega=\\{x&gt;0, x\\in IR\\}\\) Ejercicio. Definir el espacio muestral para los siguientes experimentos Elegir 4 personas de un grupo de 30 (Combinatoria) pp&lt;-1:30 pp ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 ## [15] 15 16 17 18 19 20 21 22 23 24 25 26 27 28 ## [29] 29 30 \\[30C4=\\frac{30!}{(30-4)!4!}=27405\\] Si existen 20 mujeres y 10 hombres, elegir 2 mujeres y 2 hombres. (Combinatoria) \\[20C2*10C2=8550\\] Se tienen 5 libros; biología, estadística, matemática, álgebra y una novela. Se quiere ordenar los libros en un estante. \\[5!=5*4*3*2*1=120\\] 2.2 Definición de probabilidad Clásica, teórica (espacio equilibrado, equiprobable) \\[P(A)=\\frac{CasosPosibles}{Casos Totales}=\\frac{\\#A}{\\#\\Omega}\\] Ejemplo, al lanzar un dado \\[P(Par)=\\frac{3}{6}\\] \\[P(\\text{menor a 5})=\\frac{4}{6}\\] Frecuentista Ejemplo (clásica), lanzar una moneda \\[P(Cara)=\\frac{1}{2}\\] \\[P(Cara)=lim_{N\\rightarrow \\infty} \\frac{n_{cara}}{N}\\] - A priori \\[P(llover)=0.3\\] 2.3 Propiedades de las probabilidades \\[0\\leq P(A) \\leq 1\\] \\[P(\\Omega)=1\\] Ejemplo, al lanzar un dado. \\[P(\\text{mayor a 0})=1\\] \\[P(\\varnothing)=0\\] Ejemplo, al lanzar un dado. \\[P(\\text{menor a 0})=0\\] ## Eventos mutuamente excluyentes Si dos eventos (A,B) son mutuamente excluyentes (son conjuntos disjuntos). Se cumple: \\[P(A \\cup B)=P(A\\text{ ó }B)=P(A)+P(B)\\] Ejemplo. Se lanza un dado, calcular la probabilidad que el número sea par: \\[P(par)=P(2\\cup4\\cup6)=P(2)+P(4)+P(6)=\\frac{1}{6}+\\frac{1}{6}+\\frac{1}{6}=\\frac{1}{2}\\] ¿Qué pasa cuando los eventos no son mutuamente excluyentes? \\[P(A\\cup B)=P(A)+P(B)-P(A\\cap B)\\] \\[P(par \\text{ ó } &lt;4)=P(par \\cup&lt;4)=P(par)+P(&lt;4)-P(par \\cap &lt;4)=\\] \\[=\\frac{1}{2}+\\frac{1}{2}-P(2)=1-\\frac{1}{6}=\\frac{5}{6}\\] \\[(2,4,6)\\cup (1,2,3)=1,2,3,4,6\\] \\[P(par \\text{ ó } &lt;4)=\\frac{5}{6}\\] Ejercicio. Un juego de cartas se compone de 52 cartas, teniendo 4 figuras; espada, diamante, trébol, corazón. Cada figura con 13 cartas; A, 2, 3, 4, 5, 6, 7, 8, 9, 10, J, Q (reina), K (rey). Si se selecciona al azar una carta: \\[P(espada)=\\frac{13}{52}=\\frac{1}{4}\\] \\[P(Q)=P(Q_{e}\\cup Q_{d} \\cup Q_t\\cup Q_c)=\\frac{4}{52}=\\frac{1}{13}\\] \\[P(espada \\cup Q)=\\frac{16}{52}\\] \\[P(espada \\cup Q)=P(espada)+P(Q)-P(espada\\cap Q)=\\] \\[P(espada)+P(Q)-P(Q_e)=\\frac{13}{52}+\\frac{4}{52}-\\frac{1}{52}=\\frac{16}{52}=\\frac{4}{13}\\] 2.4 Independencia en eventos Cuando realizamos eventos sucesivos/simultáneos y estos eventos son independientes entre ellos (un evento anterior no afecta al posterior). En esos casos podemos escribir la probabilidad de la siguiente forma: \\[P(A\\cap B)=P(A \\text{ y } B)=P(AB)=P(A)P(B)\\] También decimos que A y B son eventos independientes. Ejemplo: Se lanza una moneda 4 veces, cuál es la probabilidad de obtener cara en los 4 lanzamientos. \\[P(C_1\\cap C_2\\cap C_3\\cap C_4 )=P(C_1)*P(C_2)*P(C_3)*P(C_4)=\\frac{1}{2^4}=\\frac{1}{16}\\] Ejercicio Un estudiante decide responder al azar un examen de 100 preguntas de falso/verdadero. Calcular la probabilidad de que el estudiante acierte todas las preguntas. Solución, imaginemos cualquier pregunta. Por ejemplo la pregunta \\(i-esima\\). \\[P(C_i)=\\frac{1}{2}\\] \\[P(C_1\\cap C_2\\cap \\ldots \\cap C_{100})=P(C_1)*P(C_2)*\\ldots*P(C_{100})=\\frac{1}{2^{100}}\\] 2.5 Probabilidad condicional Evaluamos dos eventos o más simultaneamente Conocer como se altera o cambia la probabilidad de un evento a partir de la ocurrencia de otro Ejemplo, sea el experimento: Aprobar o no la materia de estadística \\(\\Omega=\\{0,1,\\ldots, 100\\}\\) \\(\\#\\Omega=101\\) \\(P(i)=\\frac{1}{101}; i=\\{0,\\ldots,100\\}\\) \\[P(Aprobar)=P(51 \\cup52 \\cup \\ldots\\cup 100)=\\frac{50}{101}\\] Suponer que se dio el primer parcial y el segundo parcial, ambos representan en conjunto el 60% de la nota, las notas de un estudiante en estos dos parciales es de 14/30 y 13/30 respectivamente. ¿Cuál es la probabilidad que el estudiante pase la materia? \\[P(Aprobar/27puntos)=\\frac{17}{41}=0.415\\] 2.5.1 Definición Sean dos eventos A y B, la probabilidad condicional de A dado B, se escribe como: \\[P(A/B)=\\frac{P(A\\cap B)}{P(B)}\\] &gt; Ejemplo En el ejemplo de las cartas calcular: \\[P(Q/espada)=\\frac{P(Q\\cap espada)}{P(espada)}=\\frac{\\frac{1}{52}}{\\frac{13}{52}}=\\frac{1}{13}\\] \\[P(espada/Q)=\\frac{P(espada \\cap Q)}{P(Q)}=\\frac{\\frac{1}{52}}{\\frac{4}{52}}=\\frac{1}{4}\\] Nota: \\[P(A \\cap B)=P(B \\cap A)\\] \\[P(A \\cup B)=P(B \\cup A)\\] \\[P(A/B) \\neq P(B/A) \\] Si A y B son independientes \\[P(A/B)=\\frac{P(A\\cap B)}{P(B)}=\\frac{P(A)*P(B)}{P(B)}=P(A)\\] Tarea: Investigar que es la distribución normal y su uso en la biología. 2.6 Variable aleatoria "],["distribución-normal.html", "3 Distribución normal 3.1 Distribución normal estándar", " 3 Distribución normal \\[f(x)=\\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\] curve(dnorm(x,20,5),xlim=c(0,40)) 3.1 Distribución normal estándar Sea \\[Z\\sim N(\\mu=0,\\sigma=1)=N(0,1)\\] Entonces, se dice que \\(Z\\) se distribuye como una normal estándar. Con su función de densidad: \\[f(z)=\\frac{1}{\\sqrt{2\\pi}} e^{-z^2}\\] Se recurre a la normal estándar debido a que existen tablas de probabilidad construidas para esta, ya que la integración convencional de la función \\(f(z)\\) no es directa. curve(dnorm(x,0,1),xlim=c(-4,4),main=&quot;Normal estándar&quot;) \\[P(Z&lt;0)=0.5\\] El uso de la tabla: la tabla devuelve las probabilidades acumuladas hasta un punto \\(t\\) \\[P(Z&lt;t)=\\phi(t)\\] \\[P(Z&lt;1.5)=\\phi(1.5)=0.9332\\] \\[P(Z&lt;0.5)=\\phi(0.5)=0.6915\\] \\[P(Z&lt;-0.76)=\\phi(-0.76)=0.2236\\] \\[P(Z&lt; -1.56)=\\phi(-1.56)=0.0594\\] \\[P(Z&lt; 2.89)=\\phi(2.89)=0.9981\\] Cuando se pide este tipo de probabilidades: \\[P(Z&gt;t)=1-P(Z\\leq t)=1-\\phi(t)\\] \\[P(a&lt;Z&lt;b)=\\phi(b)-\\phi(a), \\quad b&gt;a\\] \\[P(Z&gt;1.87)=1-\\phi(1.87)=1-0.9693=0.0307\\] \\[P(Z&gt;1.5)=1-\\phi(1.5)=1-0.9332=0.0668\\] \\[P(-1.89&lt;Z&lt;2.57)=\\phi(2.57)-\\phi(-1.89)=0.9949-0.0294=0.9655\\] Para trabajar sobre cualquier variable \\(X\\) que se distribuya normal y obtener sus probabilidades, es necesario hacer el proceso que se denomina estandarización: \\[Z=\\frac{X-\\mu}{\\sigma}\\] Así, \\(Z\\sim N(0,1)\\). Ejemplo, sea \\(X\\) que se distribuye como una normal con media \\(\\mu=24\\) y desviación estándar de \\(\\sigma=4\\), calcular las probabilidades: \\[P(X&lt;30)=P\\left(\\frac{X-\\mu}{\\sigma} &lt; \\frac{30-24}{4} \\right)=P(Z&lt;1.5)=\\phi(1.5)=0.9332\\] \\[P(X&gt;29)=P(Z&gt;1.25)=1-\\phi(1.25)=1-0.8944=0.1056\\] \\[P(20&lt;X&lt;31)=P\\left(\\frac{20-24}{4} &lt;\\frac{X-\\mu}{\\sigma} &lt;\\frac{31-24}{4} \\right)=P(-1&lt;Z&lt;1.75)=\\] \\[=\\phi(1.75)-\\phi(-1)=0.9599-0.1587=0.8012\\] Ejercicio, sea X la altura en centimetros de un grupo de estudiantes, de tal forma que esta altura de distribuye de forma normal, con media 164 y desviación estándar de 10: si se elige un estudiante al azar, calcular la probabilidad que este estudiante tenga una altura mayor a 170. Suponer que existen 60 estudiantes, estimar cuántos estudiantes tendrán una altura entre 160 y 170 Solución, \\(X\\sim N(\\mu=164,\\sigma=10)\\) \\[P(X&gt;170)=P(Z&gt;0.6)=1-\\phi(0.6)=1-0.7257=0.2743\\] \\[P(160&lt;X&lt;170)=P(-0.4&lt;Z&lt;0.6)=\\phi(0.6)-\\phi(-04)=\\] \\[=0.7257- 0.3446=0.3811\\] Qué pasara con 60 estudiantes? \\(n*Pr(.)\\) \\[n*P(160&lt;X&lt;170)=60*0.3811=22.866\\approx 23\\] "],["muestreo-y-estimaciones.html", "4 Muestreo y estimaciones 4.1 Conceptos 4.2 Distribuciones muestrales 4.3 Teorema del limite central 4.4 Distribución muestral de la media para muestras de 30 o más 4.5 Intervalo de confianza, límites de confianza 4.6 pruebas de hipótesis", " 4 Muestreo y estimaciones 4.1 Conceptos Población (universo) (\\(U\\)): La colección completa de los elementos de interés. Muestra (\\(s\\)): Un subcobjunto de la población de interés o el universo. \\[s \\subset U\\] Muestreo: El mecanismo utilizado para extraer la muestra del universo, en la estadística se valora principalmente a un mecanismo aleatorio, esto debido a las propiedades que este genera (Muestra valida estadísticamente). Inferencia: Es un área de la estadística que busca a partir de una muestra estadísticamente valida describir a la población de estudio. Mediante la inferencia descriptiva, inferencia predictiva y la inferencia causal. Parámetro: Una función sobre la población \\[\\theta=f(U,X)\\] Estadística: Una función sobre la muestra \\[Estadística=f(s,X)\\] Estimador: Es una estadística, que tiene el objetivo de aproximar a un parámetro \\[\\hat{\\theta}=f(s,X)\\] Ejemplo. En una población de estudiantes de tamaño \\(N=10\\), se tiene el gasto en transporte a la universidad en un día común. Se extrae una muestra de tamaño 4, proponer estimadores para el total del gasto en transporte. x&lt;-c(2,4,5,5,2,10,15,7,4,2) sum(x)#parámetro del total ## [1] 56 s&lt;-sample(x,4) s&lt;-c(5,5,2,7) s2&lt;-sample(x,4) s2&lt;-c(10,5,5,15) \\[\\hat{\\theta}_1=\\sum_s x_i+n*N =5+5+2+7+40=\\{59,75\\}\\] \\[\\hat{\\theta}_2=n\\sum_{s,&lt;&gt;}x_i=(5+2+7)*4=\\{56,120\\}\\] \\[\\hat{\\theta}_3=\\frac{1}{x_{max}}\\prod_s x_i= \\frac{5*5*2*7}{7}=\\{50,250\\}\\] \\[\\hat{\\theta}_4=\\frac{N\\sum_s x_i}{n}=N*\\bar{x}=\\frac{10*(5+5+2+7)}{4}=\\{47.5,87.5\\}\\] ¿Cuántas muestras posibles se pueden construir en el ejercicio anterior? Si las muestras son sin reposición la cantidad de muestras posibles es determinada por: \\[NCn=10C4=\\frac{10!}{6!*4!}=210\\] combn(x,4) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 2 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 4 4 ## [3,] 5 5 5 5 5 5 5 5 ## [4,] 5 2 10 15 7 4 2 2 ## [,9] [,10] [,11] [,12] [,13] [,14] [,15] ## [1,] 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 4 ## [3,] 5 5 5 5 5 2 2 ## [4,] 10 15 7 4 2 10 15 ## [,16] [,17] [,18] [,19] [,20] [,21] [,22] ## [1,] 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 4 ## [3,] 2 2 2 10 10 10 10 ## [4,] 7 4 2 15 7 4 2 ## [,23] [,24] [,25] [,26] [,27] [,28] [,29] ## [1,] 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 5 ## [3,] 15 15 15 7 7 4 5 ## [4,] 7 4 2 4 2 2 2 ## [,30] [,31] [,32] [,33] [,34] [,35] [,36] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 5 5 5 5 5 2 2 ## [4,] 10 15 7 4 2 10 15 ## [,37] [,38] [,39] [,40] [,41] [,42] [,43] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 2 2 2 10 10 10 10 ## [4,] 7 4 2 15 7 4 2 ## [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 15 15 15 7 7 4 2 ## [4,] 7 4 2 4 2 2 10 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 2 2 2 2 10 10 10 ## [4,] 15 7 4 2 15 7 4 ## [,58] [,59] [,60] [,61] [,62] [,63] [,64] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 10 15 15 15 7 7 4 ## [4,] 2 7 4 2 4 2 2 ## [,65] [,66] [,67] [,68] [,69] [,70] [,71] ## [1,] 2 2 2 2 2 2 2 ## [2,] 2 2 2 2 2 2 2 ## [3,] 10 10 10 10 15 15 15 ## [4,] 15 7 4 2 7 4 2 ## [,72] [,73] [,74] [,75] [,76] [,77] [,78] ## [1,] 2 2 2 2 2 2 2 ## [2,] 2 2 2 10 10 10 10 ## [3,] 7 7 4 15 15 15 7 ## [4,] 4 2 2 7 4 2 4 ## [,79] [,80] [,81] [,82] [,83] [,84] [,85] ## [1,] 2 2 2 2 2 2 4 ## [2,] 10 10 15 15 15 7 5 ## [3,] 7 4 7 7 4 4 5 ## [4,] 2 2 4 2 2 2 2 ## [,86] [,87] [,88] [,89] [,90] [,91] [,92] ## [1,] 4 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 5 ## [3,] 5 5 5 5 5 2 2 ## [4,] 10 15 7 4 2 10 15 ## [,93] [,94] [,95] [,96] [,97] [,98] [,99] ## [1,] 4 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 5 ## [3,] 2 2 2 10 10 10 10 ## [4,] 7 4 2 15 7 4 2 ## [,100] [,101] [,102] [,103] [,104] [,105] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,106] [,107] [,108] [,109] [,110] [,111] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 ## [3,] 2 2 2 2 2 10 ## [4,] 10 15 7 4 2 15 ## [,112] [,113] [,114] [,115] [,116] [,117] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 ## [3,] 10 10 10 15 15 15 ## [4,] 7 4 2 7 4 2 ## [,118] [,119] [,120] [,121] [,122] [,123] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 2 2 2 ## [3,] 7 7 4 10 10 10 ## [4,] 4 2 2 15 7 4 ## [,124] [,125] [,126] [,127] [,128] [,129] ## [1,] 4 4 4 4 4 4 ## [2,] 2 2 2 2 2 2 ## [3,] 10 15 15 15 7 7 ## [4,] 2 7 4 2 4 2 ## [,130] [,131] [,132] [,133] [,134] [,135] ## [1,] 4 4 4 4 4 4 ## [2,] 2 10 10 10 10 10 ## [3,] 4 15 15 15 7 7 ## [4,] 2 7 4 2 4 2 ## [,136] [,137] [,138] [,139] [,140] [,141] ## [1,] 4 4 4 4 4 5 ## [2,] 10 15 15 15 7 5 ## [3,] 4 7 7 4 4 2 ## [4,] 2 4 2 2 2 10 ## [,142] [,143] [,144] [,145] [,146] [,147] ## [1,] 5 5 5 5 5 5 ## [2,] 5 5 5 5 5 5 ## [3,] 2 2 2 2 10 10 ## [4,] 15 7 4 2 15 7 ## [,148] [,149] [,150] [,151] [,152] [,153] ## [1,] 5 5 5 5 5 5 ## [2,] 5 5 5 5 5 5 ## [3,] 10 10 15 15 15 7 ## [4,] 4 2 7 4 2 4 ## [,154] [,155] [,156] [,157] [,158] [,159] ## [1,] 5 5 5 5 5 5 ## [2,] 5 5 2 2 2 2 ## [3,] 7 4 10 10 10 10 ## [4,] 2 2 15 7 4 2 ## [,160] [,161] [,162] [,163] [,164] [,165] ## [1,] 5 5 5 5 5 5 ## [2,] 2 2 2 2 2 2 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,166] [,167] [,168] [,169] [,170] [,171] ## [1,] 5 5 5 5 5 5 ## [2,] 10 10 10 10 10 10 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,172] [,173] [,174] [,175] [,176] [,177] ## [1,] 5 5 5 5 5 5 ## [2,] 15 15 15 7 2 2 ## [3,] 7 7 4 4 10 10 ## [4,] 4 2 2 2 15 7 ## [,178] [,179] [,180] [,181] [,182] [,183] ## [1,] 5 5 5 5 5 5 ## [2,] 2 2 2 2 2 2 ## [3,] 10 10 15 15 15 7 ## [4,] 4 2 7 4 2 4 ## [,184] [,185] [,186] [,187] [,188] [,189] ## [1,] 5 5 5 5 5 5 ## [2,] 2 2 10 10 10 10 ## [3,] 7 4 15 15 15 7 ## [4,] 2 2 7 4 2 4 ## [,190] [,191] [,192] [,193] [,194] [,195] ## [1,] 5 5 5 5 5 5 ## [2,] 10 10 15 15 15 7 ## [3,] 7 4 7 7 4 4 ## [4,] 2 2 4 2 2 2 ## [,196] [,197] [,198] [,199] [,200] [,201] ## [1,] 2 2 2 2 2 2 ## [2,] 10 10 10 10 10 10 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,202] [,203] [,204] [,205] [,206] [,207] ## [1,] 2 2 2 2 10 10 ## [2,] 15 15 15 7 15 15 ## [3,] 7 7 4 4 7 7 ## [4,] 4 2 2 2 4 2 ## [,208] [,209] [,210] ## [1,] 10 10 15 ## [2,] 15 7 7 ## [3,] 4 4 4 ## [4,] 2 2 2 choose(10,4) ## [1] 210 format(choose(800,20),scientific = F) ## [1] &quot;3729767602055710168420662226248440888622&quot; 4.2 Distribuciones muestrales Es la forma o el comportamiento de las muestras posibles respecto algún estimador, su importancia se debe a la posibilidad de estudiar el fenómeno completo e identificar patrones. ss&lt;-combn(x,4) t1&lt;-apply(ss,2,sum)+4*10 t2&lt;-sapply(apply(ss,2,unique), sum)*4 t3&lt;-apply(ss,2,prod)/apply(ss,2,max) t4&lt;-apply(ss,2,mean)*10 tt&lt;-cbind(t1,t2,t3,t4) #representante apply(tt,2,mean) ## t1 t2 t3 t4 ## 62.40000 81.86667 58.27619 56.00000 #variabilidad apply(tt,2,sd) ## t1 t2 t3 t4 ## 6.431978 30.140045 56.625437 16.079944 #gráfica par(mfrow=c(2,2)) hist(t1,xlim=c(0,100));hist(t2,xlim=c(0,100));hist(t3,xlim=c(0,100));hist(t4,xlim=c(0,100)) boxplot(t1);boxplot(t2);boxplot(t3);boxplot(t4) plot(density(t1));abline(v=56);plot(density(t2));abline(v=56);plot(density(t3));abline(v=56);plot(density(t4));abline(v=56) Los estimadores \\(\\hat{\\theta}\\) finalmente son variables aleatorias ya que a priori no sabemos el resultado antes de sacar la muestra respectiva. Cuyo recorrido de esta variable aleatoria es dada por los distintos valores que obtienen de las muestras posibles. Existen dos criterios prácticos para calificar la calidad de un estimador: Estimador insesgado (más relevante): Se refiere a que el centro de la distribución es el parámetro de interés, de manera formal: \\[E[\\hat{\\theta}]=\\theta\\] Estimador eficiente: La idea de eficiencia en los estimadores se mide con la varianza del estimador, el estimador con menor varianza es el más eficiente. Por ejemplo: \\[V(\\hat{\\theta}_1)&gt;V(\\hat{\\theta}_2)\\] \\(\\hat{\\theta}_2\\) es más eficiente que \\(\\hat{\\theta}_1\\) Existen estimadores clásicos y frecuentemente usados que son estimadores insesgados, entre ellos: 4.2.1 Media Parámetro \\[\\mu_x=\\frac{\\sum_U x_i}{N}\\] Estimador (media muestral) \\[\\bar{x}=\\frac{\\sum_s x_i}{n}\\] 4.2.2 Diferencia de medias Es una medida que compara dos poblaciones Parámetro \\[\\mu_1-\\mu_2=\\frac{\\sum_{U_1} x_i}{N_1}-\\frac{\\sum_{U_2} x_i}{N_2}\\] Estimador (medias muestrales) \\[\\bar{x}_1-\\bar{x}_2=\\frac{\\sum_{s_1} x_i}{n_1}-\\frac{\\sum_{s_2} x_i}{n_2}\\] ### Total Parámetro \\[t_x=\\sum_U x_i\\] Estimador \\[\\hat{t}_x=N*\\frac{\\sum_s x_i}{n}=N*\\bar{x}\\] 4.2.3 Proporción Es una medida que identifica la proporción de participación de alguna característica de interés Parámetro \\[P_A=\\frac{\\#A}{N}=\\frac{\\sum_U x_i}{N}; \\quad \\{x_i=1 \\quad i \\in A, x_i=0 \\quad eoc\\}\\] Estimador \\[\\hat{P}_A=\\frac{\\#a}{n}=\\frac{\\sum_s x_i}{n}; \\quad \\{x_i=1 \\quad i \\in A, x_i=0 \\quad eoc\\}\\] 4.3 Teorema del limite central Si \\(\\bar{x}\\) es la media muestral de una muestra aleatoria de tamaño \\(n\\) tomada de una población \\(U\\) con media poblacional \\(\\mu_x\\) y varianza finita (se puede calcular) \\(\\sigma_x^2\\). Entonces la forma limite de la distribución de \\(\\bar{x}\\) a medida que \\(n\\rightarrow \\infty\\) crece, se puede asegurar: \\[\\bar{x}\\sim N\\left(\\mu=\\mu_x,\\sigma^2=\\frac{\\sigma^2_x}{n}\\right)\\] Nota: Esta idea de \\(n\\) grande, en estadística tradicionalmente se toma como grande cuando \\(n\\geq 30\\), hay textos que plantean \\(n\\geq 20\\). Ejemplo: Recordar la idea de una distribución muestral: x&lt;-c(2,4,5,5,2,10,15,7,4,2) n&lt;-4 choose(10,4) ## [1] 210 ss&lt;-combn(x,4) ss ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 2 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 4 4 ## [3,] 5 5 5 5 5 5 5 5 ## [4,] 5 2 10 15 7 4 2 2 ## [,9] [,10] [,11] [,12] [,13] [,14] [,15] ## [1,] 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 4 ## [3,] 5 5 5 5 5 2 2 ## [4,] 10 15 7 4 2 10 15 ## [,16] [,17] [,18] [,19] [,20] [,21] [,22] ## [1,] 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 4 ## [3,] 2 2 2 10 10 10 10 ## [4,] 7 4 2 15 7 4 2 ## [,23] [,24] [,25] [,26] [,27] [,28] [,29] ## [1,] 2 2 2 2 2 2 2 ## [2,] 4 4 4 4 4 4 5 ## [3,] 15 15 15 7 7 4 5 ## [4,] 7 4 2 4 2 2 2 ## [,30] [,31] [,32] [,33] [,34] [,35] [,36] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 5 5 5 5 5 2 2 ## [4,] 10 15 7 4 2 10 15 ## [,37] [,38] [,39] [,40] [,41] [,42] [,43] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 2 2 2 10 10 10 10 ## [4,] 7 4 2 15 7 4 2 ## [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 15 15 15 7 7 4 2 ## [4,] 7 4 2 4 2 2 10 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 2 2 2 2 10 10 10 ## [4,] 15 7 4 2 15 7 4 ## [,58] [,59] [,60] [,61] [,62] [,63] [,64] ## [1,] 2 2 2 2 2 2 2 ## [2,] 5 5 5 5 5 5 5 ## [3,] 10 15 15 15 7 7 4 ## [4,] 2 7 4 2 4 2 2 ## [,65] [,66] [,67] [,68] [,69] [,70] [,71] ## [1,] 2 2 2 2 2 2 2 ## [2,] 2 2 2 2 2 2 2 ## [3,] 10 10 10 10 15 15 15 ## [4,] 15 7 4 2 7 4 2 ## [,72] [,73] [,74] [,75] [,76] [,77] [,78] ## [1,] 2 2 2 2 2 2 2 ## [2,] 2 2 2 10 10 10 10 ## [3,] 7 7 4 15 15 15 7 ## [4,] 4 2 2 7 4 2 4 ## [,79] [,80] [,81] [,82] [,83] [,84] [,85] ## [1,] 2 2 2 2 2 2 4 ## [2,] 10 10 15 15 15 7 5 ## [3,] 7 4 7 7 4 4 5 ## [4,] 2 2 4 2 2 2 2 ## [,86] [,87] [,88] [,89] [,90] [,91] [,92] ## [1,] 4 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 5 ## [3,] 5 5 5 5 5 2 2 ## [4,] 10 15 7 4 2 10 15 ## [,93] [,94] [,95] [,96] [,97] [,98] [,99] ## [1,] 4 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 5 ## [3,] 2 2 2 10 10 10 10 ## [4,] 7 4 2 15 7 4 2 ## [,100] [,101] [,102] [,103] [,104] [,105] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,106] [,107] [,108] [,109] [,110] [,111] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 ## [3,] 2 2 2 2 2 10 ## [4,] 10 15 7 4 2 15 ## [,112] [,113] [,114] [,115] [,116] [,117] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 5 5 5 ## [3,] 10 10 10 15 15 15 ## [4,] 7 4 2 7 4 2 ## [,118] [,119] [,120] [,121] [,122] [,123] ## [1,] 4 4 4 4 4 4 ## [2,] 5 5 5 2 2 2 ## [3,] 7 7 4 10 10 10 ## [4,] 4 2 2 15 7 4 ## [,124] [,125] [,126] [,127] [,128] [,129] ## [1,] 4 4 4 4 4 4 ## [2,] 2 2 2 2 2 2 ## [3,] 10 15 15 15 7 7 ## [4,] 2 7 4 2 4 2 ## [,130] [,131] [,132] [,133] [,134] [,135] ## [1,] 4 4 4 4 4 4 ## [2,] 2 10 10 10 10 10 ## [3,] 4 15 15 15 7 7 ## [4,] 2 7 4 2 4 2 ## [,136] [,137] [,138] [,139] [,140] [,141] ## [1,] 4 4 4 4 4 5 ## [2,] 10 15 15 15 7 5 ## [3,] 4 7 7 4 4 2 ## [4,] 2 4 2 2 2 10 ## [,142] [,143] [,144] [,145] [,146] [,147] ## [1,] 5 5 5 5 5 5 ## [2,] 5 5 5 5 5 5 ## [3,] 2 2 2 2 10 10 ## [4,] 15 7 4 2 15 7 ## [,148] [,149] [,150] [,151] [,152] [,153] ## [1,] 5 5 5 5 5 5 ## [2,] 5 5 5 5 5 5 ## [3,] 10 10 15 15 15 7 ## [4,] 4 2 7 4 2 4 ## [,154] [,155] [,156] [,157] [,158] [,159] ## [1,] 5 5 5 5 5 5 ## [2,] 5 5 2 2 2 2 ## [3,] 7 4 10 10 10 10 ## [4,] 2 2 15 7 4 2 ## [,160] [,161] [,162] [,163] [,164] [,165] ## [1,] 5 5 5 5 5 5 ## [2,] 2 2 2 2 2 2 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,166] [,167] [,168] [,169] [,170] [,171] ## [1,] 5 5 5 5 5 5 ## [2,] 10 10 10 10 10 10 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,172] [,173] [,174] [,175] [,176] [,177] ## [1,] 5 5 5 5 5 5 ## [2,] 15 15 15 7 2 2 ## [3,] 7 7 4 4 10 10 ## [4,] 4 2 2 2 15 7 ## [,178] [,179] [,180] [,181] [,182] [,183] ## [1,] 5 5 5 5 5 5 ## [2,] 2 2 2 2 2 2 ## [3,] 10 10 15 15 15 7 ## [4,] 4 2 7 4 2 4 ## [,184] [,185] [,186] [,187] [,188] [,189] ## [1,] 5 5 5 5 5 5 ## [2,] 2 2 10 10 10 10 ## [3,] 7 4 15 15 15 7 ## [4,] 2 2 7 4 2 4 ## [,190] [,191] [,192] [,193] [,194] [,195] ## [1,] 5 5 5 5 5 5 ## [2,] 10 10 15 15 15 7 ## [3,] 7 4 7 7 4 4 ## [4,] 2 2 4 2 2 2 ## [,196] [,197] [,198] [,199] [,200] [,201] ## [1,] 2 2 2 2 2 2 ## [2,] 10 10 10 10 10 10 ## [3,] 15 15 15 7 7 4 ## [4,] 7 4 2 4 2 2 ## [,202] [,203] [,204] [,205] [,206] [,207] ## [1,] 2 2 2 2 10 10 ## [2,] 15 15 15 7 15 15 ## [3,] 7 7 4 4 7 7 ## [4,] 4 2 2 2 4 2 ## [,208] [,209] [,210] ## [1,] 10 10 15 ## [2,] 15 7 7 ## [3,] 4 4 4 ## [4,] 2 2 2 #distribución de la media mm&lt;-apply(ss,2,mean) mm ## [1] 4.00 3.25 5.25 6.50 4.50 3.75 3.25 3.25 ## [9] 5.25 6.50 4.50 3.75 3.25 4.50 5.75 3.75 ## [17] 3.00 2.50 7.75 5.75 5.00 4.50 7.00 6.25 ## [25] 5.75 4.25 3.75 3.00 3.50 5.50 6.75 4.75 ## [33] 4.00 3.50 4.75 6.00 4.00 3.25 2.75 8.00 ## [41] 6.00 5.25 4.75 7.25 6.50 6.00 4.50 4.00 ## [49] 3.25 4.75 6.00 4.00 3.25 2.75 8.00 6.00 ## [57] 5.25 4.75 7.25 6.50 6.00 4.50 4.00 3.25 ## [65] 7.25 5.25 4.50 4.00 6.50 5.75 5.25 3.75 ## [73] 3.25 2.50 8.50 7.75 7.25 5.75 5.25 4.50 ## [81] 7.00 6.50 5.75 3.75 4.00 6.00 7.25 5.25 ## [89] 4.50 4.00 5.25 6.50 4.50 3.75 3.25 8.50 ## [97] 6.50 5.75 5.25 7.75 7.00 6.50 5.00 4.50 ## [105] 3.75 5.25 6.50 4.50 3.75 3.25 8.50 6.50 ## [113] 5.75 5.25 7.75 7.00 6.50 5.00 4.50 3.75 ## [121] 7.75 5.75 5.00 4.50 7.00 6.25 5.75 4.25 ## [129] 3.75 3.00 9.00 8.25 7.75 6.25 5.75 5.00 ## [137] 7.50 7.00 6.25 4.25 5.50 6.75 4.75 4.00 ## [145] 3.50 8.75 6.75 6.00 5.50 8.00 7.25 6.75 ## [153] 5.25 4.75 4.00 8.00 6.00 5.25 4.75 7.25 ## [161] 6.50 6.00 4.50 4.00 3.25 9.25 8.50 8.00 ## [169] 6.50 6.00 5.25 7.75 7.25 6.50 4.50 8.00 ## [177] 6.00 5.25 4.75 7.25 6.50 6.00 4.50 4.00 ## [185] 3.25 9.25 8.50 8.00 6.50 6.00 5.25 7.75 ## [193] 7.25 6.50 4.50 8.50 7.75 7.25 5.75 5.25 ## [201] 4.50 7.00 6.50 5.75 3.75 9.00 8.50 7.75 ## [209] 5.75 7.00 hist(mm) mean(x) #parámetro media poblacional ## [1] 5.6 mean(mm) # Insesgadez ## [1] 5.6 Vamos a simular el teorema del limite central. Imaginar que se tiene una población de 500 gatos y se quiere observar el peso en kilogramos. N&lt;-500 set.seed(855) xx&lt;-rnorm(N, 4,1.2) xx&lt;-round(xx,1) xx ## [1] 4.0 3.8 6.1 6.8 4.9 3.6 4.2 5.3 2.7 5.4 ## [11] 3.3 4.9 4.0 2.4 3.0 2.5 5.6 4.0 3.4 4.6 ## [21] 1.4 3.5 5.0 3.8 5.1 3.0 5.1 3.7 3.9 3.3 ## [31] 4.2 4.4 3.2 4.4 5.3 3.5 3.1 4.2 5.7 2.2 ## [41] 5.2 5.2 3.2 5.4 2.6 5.5 3.2 3.0 4.3 3.5 ## [51] 5.7 2.9 5.4 3.6 1.4 4.6 4.3 6.3 2.5 4.7 ## [61] 2.8 3.9 5.7 5.0 4.8 3.8 5.9 4.4 4.5 6.4 ## [71] 4.3 2.4 4.2 3.6 4.8 4.4 5.7 5.0 6.1 4.3 ## [81] 4.5 6.0 2.8 7.0 6.2 4.6 5.0 1.8 4.0 6.2 ## [91] 3.2 3.3 4.6 4.4 2.1 2.3 2.6 0.7 3.9 5.4 ## [101] 1.6 4.4 2.6 3.2 3.5 1.2 6.1 3.7 3.8 7.4 ## [111] 4.5 3.1 2.4 3.6 2.6 3.7 4.7 3.9 2.2 4.5 ## [121] 4.2 4.1 4.9 5.1 5.9 3.2 4.9 3.1 3.0 6.2 ## [131] 6.6 3.9 4.2 3.5 3.2 4.1 2.9 3.2 4.8 4.5 ## [141] 5.3 4.1 2.8 3.7 3.6 5.2 4.1 5.2 4.1 1.4 ## [151] 4.7 3.8 4.9 3.1 5.9 5.7 2.4 4.3 4.6 3.1 ## [161] 3.9 4.4 4.4 2.1 4.0 3.5 4.8 3.4 3.9 5.6 ## [171] 2.5 3.1 3.2 5.5 4.5 2.8 4.7 4.0 3.5 4.5 ## [181] 4.0 4.6 4.4 3.5 4.7 4.4 4.4 5.0 2.8 6.6 ## [191] 3.9 3.5 5.1 6.0 5.1 4.6 2.0 4.2 3.5 0.3 ## [201] 4.0 2.7 4.8 3.3 3.1 6.3 0.9 3.7 2.8 4.1 ## [211] 6.3 3.7 2.3 6.2 5.5 3.6 1.9 0.7 3.5 4.2 ## [221] 4.7 2.5 3.1 3.6 3.9 1.5 6.0 5.3 4.8 2.3 ## [231] 5.5 1.8 4.7 2.8 4.2 4.9 3.2 5.0 4.8 3.2 ## [241] 2.4 4.4 4.2 3.3 2.5 4.0 4.7 4.8 2.4 2.8 ## [251] 4.5 3.9 4.3 2.5 4.3 3.1 2.7 2.7 3.9 2.7 ## [261] 2.4 3.9 2.4 2.7 4.3 4.0 3.3 3.9 4.3 3.7 ## [271] 4.1 4.9 5.1 6.2 4.5 6.6 5.9 3.7 6.3 3.2 ## [281] 3.6 4.0 2.2 1.5 4.9 5.0 4.3 5.8 2.3 3.7 ## [291] 3.6 5.1 2.4 2.1 2.7 5.3 4.1 4.0 4.1 5.6 ## [301] 2.7 4.7 4.4 4.8 7.0 6.0 3.5 3.8 4.6 4.3 ## [311] 4.9 4.5 3.5 3.3 3.9 4.2 5.5 2.3 3.4 4.1 ## [321] 2.9 5.2 3.8 6.4 3.3 3.9 4.1 1.6 1.9 5.2 ## [331] 1.2 4.3 5.6 5.6 2.3 1.4 2.6 5.3 2.4 5.2 ## [341] 5.6 2.7 5.1 4.2 4.4 3.4 3.4 5.1 3.4 5.7 ## [351] 2.1 5.1 4.6 1.8 5.9 5.4 0.9 4.1 6.0 5.5 ## [361] 2.6 4.8 3.9 4.4 1.2 4.5 4.0 5.2 5.1 3.3 ## [371] 3.1 2.7 4.2 4.5 5.9 3.7 4.8 4.8 4.6 5.0 ## [381] 3.6 4.5 6.1 3.7 3.3 3.9 3.5 6.5 2.5 2.6 ## [391] 2.8 4.7 4.6 5.3 4.1 6.6 2.3 5.6 4.6 4.9 ## [401] 3.7 5.5 4.1 2.5 2.6 4.6 2.8 4.8 2.9 1.0 ## [411] 4.4 4.2 4.8 5.7 3.4 5.1 5.7 5.1 3.9 4.4 ## [421] 5.0 5.1 1.5 4.9 6.3 5.7 3.3 6.4 4.0 6.1 ## [431] 5.2 3.8 3.0 2.9 4.1 5.1 4.2 2.7 2.7 3.0 ## [441] 2.2 3.6 5.5 4.2 2.7 4.2 4.7 4.5 4.9 3.8 ## [451] 3.1 3.3 3.6 5.2 5.6 4.4 3.5 3.6 3.3 3.7 ## [461] 1.9 1.4 4.4 3.9 2.9 5.5 3.2 3.8 4.6 1.6 ## [471] 4.7 1.0 4.3 4.5 2.2 4.6 3.0 4.3 5.4 5.3 ## [481] 2.5 6.5 3.6 5.0 4.1 6.9 4.1 6.0 4.4 3.5 ## [491] 5.2 3.6 2.7 2.7 4.9 3.7 4.6 2.0 3.9 2.5 n&lt;-40 format(choose(N,n),scientific = F)# muestras posibles ## [1] &quot;224426968106501454848008488044444424624268244444206040840486&quot; Como no es posible estudiar a todas las muestras posibles, debido a una limitación computacional se va a obtener y estudiar una parte de estas distribuciones muestrales. k&lt;-1000 # parte de las muestras posibles mm&lt;-NULL for(i in 1:k){ maux&lt;-sample(xx,n) mm[i]&lt;-mean(maux) } mm ## [1] 3.8400 4.0325 3.6675 3.9625 4.1100 ## [6] 3.7375 4.1450 4.1175 3.7425 3.8675 ## [11] 3.9425 3.9000 4.0075 3.9650 4.0200 ## [16] 4.5675 3.9075 3.9700 3.8900 4.0775 ## [21] 4.0400 3.9025 4.2075 4.1950 3.9825 ## [26] 4.2375 4.0050 4.1150 4.1075 4.0025 ## [31] 4.4175 3.6750 3.9700 4.3025 3.9575 ## [36] 3.8550 4.0550 4.1425 3.8625 4.0575 ## [41] 4.1200 3.7825 3.8250 3.7475 4.0925 ## [46] 4.2150 3.8025 4.1325 4.0475 3.8825 ## [51] 4.0525 4.2300 3.9400 4.0450 3.9000 ## [56] 4.0600 4.1325 4.1575 3.9075 4.0250 ## [61] 3.9975 3.7975 4.0825 4.0650 3.8000 ## [66] 3.9700 4.0975 4.0550 3.4575 4.0250 ## [71] 3.7925 3.8850 3.8250 3.9475 4.0450 ## [76] 3.7250 4.0600 3.6625 3.9325 4.7300 ## [81] 3.9775 4.3350 4.1875 3.9175 3.7650 ## [86] 3.9325 4.0975 3.9200 3.7250 3.7725 ## [91] 4.1375 4.0175 4.0300 4.1675 3.9400 ## [96] 3.7875 4.0725 4.0700 4.1875 3.9625 ## [101] 4.0550 4.1175 3.9325 4.4075 3.8375 ## [106] 4.1750 4.2500 3.9550 4.1550 3.8350 ## [111] 3.9800 4.1225 3.6375 3.9450 3.8875 ## [116] 4.3850 4.0175 4.1175 3.8850 4.2700 ## [121] 4.2975 4.1250 4.0375 3.7375 3.7600 ## [126] 4.3725 4.1350 3.9850 4.1525 3.8725 ## [131] 4.4400 4.3250 3.9250 4.1650 4.1500 ## [136] 3.7600 3.9550 4.0050 3.9550 4.1650 ## [141] 4.4175 4.2675 3.8725 4.3250 3.8850 ## [146] 4.2150 4.1775 3.7950 3.5875 3.8950 ## [151] 3.8375 4.3425 3.9850 4.4450 4.1500 ## [156] 3.7125 4.0575 3.9375 4.2625 4.4575 ## [161] 3.7300 3.7900 3.8625 3.9850 4.0275 ## [166] 3.6825 3.8200 4.0775 3.9400 4.0925 ## [171] 4.1700 4.2625 4.0400 3.9550 4.2800 ## [176] 4.0975 4.0750 4.0650 4.1600 3.8200 ## [181] 4.2075 3.9075 4.3075 4.1350 3.7950 ## [186] 4.4975 4.0050 4.0450 4.2450 3.8875 ## [191] 3.8375 4.0650 3.7375 4.1300 4.2475 ## [196] 3.9500 4.0500 3.8000 4.3450 3.9275 ## [201] 3.9425 4.0200 3.7850 4.0825 4.1375 ## [206] 3.9100 4.1300 3.8650 3.8400 4.3450 ## [211] 4.0050 3.7225 4.3250 4.4775 4.1975 ## [216] 3.9350 4.1000 4.2625 3.7825 4.3450 ## [221] 3.8775 3.9975 4.0525 4.3325 3.8275 ## [226] 4.0125 3.6875 4.2425 3.8575 3.6700 ## [231] 4.0675 3.9325 4.0825 4.1925 3.8600 ## [236] 4.3700 3.9000 4.3125 4.0125 3.8500 ## [241] 4.0725 3.9725 4.1225 3.6950 3.9575 ## [246] 3.9050 3.8900 4.0975 3.8350 3.8800 ## [251] 3.7500 4.0900 4.0075 4.0750 3.9125 ## [256] 4.2025 3.9625 3.9700 3.9775 4.0300 ## [261] 4.1400 3.9175 4.0125 4.3950 3.6625 ## [266] 3.8175 4.0375 3.7575 4.0225 4.2575 ## [271] 4.2600 3.4650 3.8475 4.0800 3.9325 ## [276] 3.9425 3.8175 3.8525 4.6000 3.7900 ## [281] 4.0900 4.0825 3.7650 4.1225 4.0650 ## [286] 3.8325 4.0575 3.7300 3.9625 4.4850 ## [291] 4.1200 4.1525 3.8025 4.1250 4.1675 ## [296] 4.2375 3.8150 4.0350 4.3575 4.1900 ## [301] 3.8900 4.0900 3.8925 4.0950 4.2050 ## [306] 3.8900 3.8350 4.2050 3.8875 3.6325 ## [311] 4.5150 4.1975 4.1100 4.0475 3.8600 ## [316] 4.1125 4.1200 4.0900 3.8675 4.0100 ## [321] 3.9625 4.1300 4.0350 3.9500 4.3500 ## [326] 4.4375 3.9250 3.7875 4.2175 4.1975 ## [331] 4.1500 3.9625 4.0925 4.5075 4.2475 ## [336] 4.0750 4.5625 4.0300 4.1475 4.1175 ## [341] 3.9750 4.2425 4.0250 4.1725 4.1825 ## [346] 4.2525 3.9925 4.2725 3.9025 4.0375 ## [351] 4.0900 4.0550 3.9100 4.2125 3.6725 ## [356] 4.1925 3.9825 4.4400 3.7075 3.9825 ## [361] 3.7000 3.9975 4.1475 4.0625 3.5075 ## [366] 3.6225 3.6875 4.3575 3.9975 3.7950 ## [371] 4.2100 4.2500 3.8175 3.7300 4.1850 ## [376] 4.3575 4.1750 3.6375 4.1950 3.9525 ## [381] 3.8225 4.0600 3.9350 3.9650 4.0600 ## [386] 4.1550 4.0450 3.9075 3.9175 4.3700 ## [391] 4.0025 4.2175 3.9625 4.3975 4.1400 ## [396] 4.3625 4.2375 3.9075 3.8525 4.1250 ## [401] 3.8950 3.9475 3.8725 4.0100 4.2175 ## [406] 4.1700 3.9400 4.0325 4.1150 4.3025 ## [411] 3.7925 3.9575 4.1375 4.1400 3.8175 ## [416] 3.8700 3.9525 4.1575 4.0600 4.0825 ## [421] 3.8150 3.8100 3.6300 3.7150 3.7925 ## [426] 4.0775 3.9625 4.0550 3.8175 4.1225 ## [431] 4.0125 3.7900 3.9025 4.2125 3.9450 ## [436] 4.5725 4.0950 4.2775 3.8275 4.4175 ## [441] 4.1025 3.9050 3.7425 4.2425 4.1525 ## [446] 3.8100 4.3850 3.9850 4.2475 4.0675 ## [451] 3.9375 3.8200 4.0575 3.9600 3.7200 ## [456] 3.8150 3.8975 4.0150 4.1675 4.1325 ## [461] 4.0100 4.1350 3.8750 4.2600 4.2300 ## [466] 3.5800 3.8450 3.9925 3.9600 4.2025 ## [471] 3.7875 4.3750 3.9350 4.2600 4.1350 ## [476] 4.2000 4.2050 3.9475 4.0425 4.1400 ## [481] 4.0975 4.3225 3.5725 4.3450 4.0250 ## [486] 3.8250 4.1625 4.3050 3.8975 4.2950 ## [491] 3.9175 3.9400 3.6500 3.8300 3.9025 ## [496] 4.1825 3.9200 4.2975 3.7675 4.2300 ## [501] 4.1300 4.2275 4.1100 3.8325 4.1275 ## [506] 3.9875 4.0100 4.2275 4.0275 4.2275 ## [511] 3.9725 4.1775 3.6800 4.3125 3.9425 ## [516] 4.3825 4.0650 4.4725 4.4600 4.0700 ## [521] 3.9825 4.2125 4.3325 4.1225 3.8975 ## [526] 4.2950 4.3475 4.1125 3.8075 3.9500 ## [531] 4.1725 4.0425 4.1450 3.8600 4.1200 ## [536] 4.1200 4.3625 4.0475 4.2575 3.8375 ## [541] 4.2075 3.8650 3.9700 3.9750 3.9125 ## [546] 4.3950 3.9675 4.0400 3.9250 3.6800 ## [551] 3.9975 3.9550 4.0850 3.8775 3.8475 ## [556] 4.4525 4.3250 4.0775 3.9825 3.8425 ## [561] 3.8350 4.3450 4.0775 4.1575 4.1175 ## [566] 3.9550 4.0600 3.9775 4.1225 4.2125 ## [571] 3.8050 3.9475 4.3075 3.7300 4.1775 ## [576] 4.0425 3.8825 4.2700 3.8825 4.0850 ## [581] 3.9200 4.1150 3.8975 3.7775 4.2675 ## [586] 4.0300 4.0875 3.8175 3.7775 4.2900 ## [591] 4.1650 3.7525 4.2300 3.9150 3.8775 ## [596] 3.8075 3.7900 3.9525 3.9575 4.3650 ## [601] 4.2325 3.9000 4.2475 4.0600 4.4425 ## [606] 4.0525 3.9250 3.7425 3.9300 4.3350 ## [611] 4.0475 3.9950 3.8275 3.9650 3.7575 ## [616] 4.2200 4.1350 4.0375 3.8200 3.7725 ## [621] 4.0350 3.9850 3.9075 4.3125 3.9825 ## [626] 4.2325 4.1725 4.0700 4.0250 3.9925 ## [631] 3.7075 3.9350 3.8450 3.8075 4.3650 ## [636] 3.9675 3.9600 4.1275 3.9975 4.1825 ## [641] 4.0350 4.1425 4.0700 4.2950 3.9475 ## [646] 3.8800 3.8100 4.3700 4.1200 3.8600 ## [651] 4.0625 3.8025 3.8400 3.8825 4.1425 ## [656] 4.0250 3.9225 3.9500 4.2000 3.9150 ## [661] 3.6025 4.2500 3.6000 3.9175 3.9600 ## [666] 4.1975 4.4675 3.8375 4.0850 3.9650 ## [671] 4.1500 4.1175 4.0550 4.0125 4.0325 ## [676] 3.8500 4.0475 3.7775 4.1350 4.0225 ## [681] 3.9750 3.8925 4.3575 4.3175 4.1100 ## [686] 4.3975 3.8700 3.8675 4.2875 4.1300 ## [691] 4.0175 4.0100 3.9100 4.1650 3.8125 ## [696] 3.7500 4.1500 4.0425 4.2300 3.9975 ## [701] 3.9725 3.9775 3.7975 3.9600 4.1675 ## [706] 4.0550 4.0350 4.1600 4.0050 3.8125 ## [711] 3.7050 4.3900 4.1775 3.8175 4.3075 ## [716] 4.1150 3.9950 4.0700 3.7425 4.4250 ## [721] 3.7025 3.9300 3.8500 4.4650 4.0325 ## [726] 4.2200 3.8825 4.1225 4.0025 4.1475 ## [731] 3.9000 4.1150 3.9850 4.0975 4.2425 ## [736] 4.0300 4.1250 4.2000 3.8125 3.8150 ## [741] 4.2925 3.8925 3.9375 3.8800 3.9250 ## [746] 4.0075 4.0875 4.2650 3.8150 4.0125 ## [751] 4.2275 4.0300 4.0075 3.9225 4.1125 ## [756] 4.1875 3.8450 4.2350 4.0450 4.3025 ## [761] 3.8300 4.4925 4.0200 3.8000 4.2800 ## [766] 3.8525 3.7925 4.0025 4.1975 3.8750 ## [771] 3.9550 4.0175 4.0450 4.0175 4.1575 ## [776] 4.0600 4.2550 3.9075 4.3400 4.2350 ## [781] 3.7400 4.0300 4.1200 4.0400 3.8825 ## [786] 3.8725 4.2575 3.9100 4.2300 3.8150 ## [791] 4.1550 4.0925 3.6575 4.1150 3.9675 ## [796] 4.0650 3.9800 4.0300 4.0725 4.0300 ## [801] 4.0375 3.8275 3.8350 4.4175 4.0050 ## [806] 4.4850 4.2525 4.0500 4.2850 3.8250 ## [811] 4.0725 4.0425 4.3525 3.9800 3.9100 ## [816] 3.8300 4.1475 3.7400 3.9675 4.1850 ## [821] 4.0000 4.2450 3.7950 4.1975 4.3175 ## [826] 3.9225 4.0325 3.9900 4.2025 3.8875 ## [831] 3.8875 3.8600 3.6350 4.3625 4.1400 ## [836] 4.1150 3.8925 4.1000 3.9675 4.2575 ## [841] 3.8425 4.0625 3.8375 3.8350 4.0000 ## [846] 4.0000 3.8350 4.0225 4.1725 3.9600 ## [851] 3.8525 4.0025 3.9875 3.6925 4.0025 ## [856] 3.6925 3.3325 4.0500 3.9850 3.6200 ## [861] 4.5550 4.0750 3.9150 4.0175 3.6100 ## [866] 4.1375 4.4825 3.9500 4.1950 4.1325 ## [871] 3.8800 4.0250 4.4650 4.0800 3.5950 ## [876] 4.0425 4.5400 4.0175 3.9700 3.7375 ## [881] 4.2025 4.0400 4.0050 3.9925 3.7325 ## [886] 4.2450 4.2850 3.7075 3.6800 4.2700 ## [891] 4.0150 3.7550 4.1875 4.0625 4.2250 ## [896] 4.4225 4.2750 3.8375 4.3575 4.0575 ## [901] 4.1675 4.0425 4.1375 4.0625 4.1250 ## [906] 4.1750 3.7725 4.1650 4.0450 4.0425 ## [911] 4.5100 4.0375 4.3350 4.0100 3.9400 ## [916] 3.9575 3.8300 3.7875 3.8475 3.9025 ## [921] 4.3675 4.0950 3.8925 3.9625 4.1750 ## [926] 4.2375 4.2175 3.8525 4.2875 4.1450 ## [931] 4.3400 3.7500 4.1150 4.0975 3.8450 ## [936] 4.1450 4.2825 3.9775 4.1475 3.9350 ## [941] 3.8075 4.1425 4.0225 4.0850 3.9400 ## [946] 4.2175 4.0725 4.0600 4.1175 4.1000 ## [951] 3.9950 4.0475 3.8825 3.8575 4.3650 ## [956] 3.9250 3.9525 4.2625 4.2525 3.7050 ## [961] 3.8500 3.9825 4.1850 3.8900 4.2225 ## [966] 3.8650 3.7675 4.1850 4.1050 3.9925 ## [971] 4.0675 4.0575 4.1650 4.1175 3.7625 ## [976] 4.0400 4.1525 4.2500 3.8750 3.6900 ## [981] 3.8275 3.9225 4.1375 4.2075 4.1675 ## [986] 4.2675 3.8750 3.9375 4.1100 3.8325 ## [991] 4.4075 3.8675 4.2550 3.8150 3.7375 ## [996] 4.2000 3.9475 4.2100 4.2550 3.9150 hist(mm,xlim = c(3,5)) abline(v=mean(xx),col=&quot;red&quot;,lwd=2) vx&lt;-sum((xx-mean(xx))^2)/N # la distribución teórica curve(dnorm(x,mean(xx),sqrt(vx/n)),xlim = c(3,5)) # de forma gráfica hist(mm,xlim = c(3,5),freq = F) curve(dnorm(x,mean(xx),sqrt(vx/n)),add=T,col=&quot;red&quot;,lwd=2) Nota: El teorema del limite central supone poblaciones grandes (infinitas) Nota: Cuando las poblaciones son pequeñas el teorema del limite central se puede seguir usando, sin embargo, la convergencia a la normalidad no estan fina 4.4 Distribución muestral de la media para muestras de 30 o más Sea \\(\\bar{x}\\) la media muestral un estimador para la media poblacional \\(\\mu_x\\). A partir del teorema de limite central y tomando en cuenta \\(n\\geq 30\\). Se puede definir a su distribución muestral como: \\[\\bar{X} \\sim N\\left(\\mu_x,\\frac{\\sigma_x^2}{n}\\right)\\approx N\\left(\\bar{x},\\frac{s^2}{n} \\right)\\] De manera general para la distribución de la media muestral podemos mencionar lo siguiente: Es un estimador insesgado, de tal forma que \\(E[\\bar{x}]=\\mu\\) La variabilidad de la media muestra es: \\[V(\\bar{x})=\\sigma^2_{\\bar{x}}=\\frac{\\sigma^2}{n}\\] La estimación de la varianza viene dada por: \\[s^2_{\\bar{x}}=\\frac{s^2}{n}\\] Este último resultado también se denomina el error estándar del estimador de la media cuando: \\[s_{\\bar{x}}=\\sqrt{\\frac{s^2}{n}}=EE(\\bar{x})\\] Ejercicio 1: Se tiene el dato del peso medido en kg. de una muestra de 9 animales: 4.0, 4.3, 4.5, 4.6, 4.7, 4.8, 4.9, 4.9, 5.1. Obtener la media muestral y el error estándar. Solución: \\[\\bar{x}=\\frac{\\sum_s x_i}{n}=\\frac{41.8}{9}=4.64\\] Para el error estándar: \\[s^2=\\frac{\\sum_s (x_i-\\bar{x})^2}{n-1}=0.1153\\] La varianza del estimador: \\[s^2_{\\bar{x}}=\\frac{0.1153}{9}=0.0128\\] Finalmente el error estándar es: \\[s_{\\bar{x}}=\\sqrt{0.0128}=0.1132\\] 4.5 Intervalo de confianza, límites de confianza Una segunda forma de aproximarse al valor real de un parámetro poblacional, es mediante un intervalo de confianza que brinda limites en los que se encuentra el verdadero valor del parámetro a un nivel determinado de confiabilidad. En términos de probabilidades, el objetivo es determinar: \\[P(L&lt;\\theta&lt;U)=1-\\alpha=\\text{Nivel de confiabilidad}\\] El valor \\(\\alpha\\) se conoce como la significancia y sus valores más usuales son de \\(0.01, 0.05,0.1\\), que respectivamente representan el 99%, 95% y 90% de confiabilidad. El objetivo ahora es determinar la forma de los límites \\(L=Lower\\) y \\(U=Upper\\), esto depende del estimador con el que se trabaje, para el estimador de la media, si usamos el teorema del límite central sabemos que: \\[\\bar{X} \\sim N\\left(\\mu_x,\\frac{\\sigma_x^2}{n}\\right)\\] Ahora, si realizamos una transformación: \\[Z=\\frac{\\bar{X}-\\mu_x}{\\frac{\\sigma_x}{\\sqrt{n}}}\\sim N(0,1)\\] Por ejemplo, para un \\(\\alpha=0.05\\) \\[P(-z_{0.05/2}&lt;Z&lt;z_{0.05/2})=0.95 \\quad(95\\%)\\] De esta forma, el intervalo de confianza de la media es: \\[IC_{1-\\alpha}(\\mu): \\bar{x} \\pm z_{\\alpha/2} *\\frac{S}{\\sqrt{n}}\\] &gt; Nota: Esta formula se aplica usando las información de la muestra, en algunos casos es posible contar con la varianza original de los datos \\(\\sigma^2\\), si esto sucede la formula es: \\[IC_{1-\\alpha}(\\mu): \\bar{x} \\pm z_{\\alpha/2} *\\frac{\\sigma}{\\sqrt{n}}\\] Los valores más comunes para confiabilidad son: 99% de confiabilidad: \\(z_{\\alpha/2}=2.58\\) 95% de confiabilidad: \\(z_{\\alpha/2}=1.96\\) 90% de confiabilidad: \\(z_{\\alpha/2}=1.64\\) Ejercicio: (Capitulo 6, ejericio 6.) El tiempo de incubación de huevos de lagarto fue medido para 24 lagartos. Estos 24 lagartos provienen de una población que tiene un \\[\\sigma^2=89.06 días^2\\] Y la media muestral \\[\\bar{x}=61.4 días\\] Calcular el IC al 99% para la media de incubación Calcular el IC al 95% para la media de incubación Calcular el IC al 90% para la media de incubación Solución Al 99%, \\[IC_{1-\\alpha}(\\mu): 61.4 \\pm 2.58 *\\sqrt{\\frac{89.06}{24}}=61.4 \\pm 4.97=\\] \\[IC_{99\\%}(\\mu): [56.43 \\quad 66.37]\\] Al 95%, \\[IC_{1-\\alpha}(\\mu): 61.4 \\pm 1.96 *\\sqrt{\\frac{89.06}{24}}=61.4 \\pm 3.78=\\] \\[IC_{95\\%}(\\mu): [57.62 \\quad 65.18]\\] Al 90%, \\[IC_{1-\\alpha}(\\mu): 61.4 \\pm 1.64 *\\sqrt{\\frac{89.06}{24}}=61.4 \\pm 3.16=\\] \\[IC_{90\\%}(\\mu): [58.24 \\quad 64.56]\\] Como un caso particular de la media se tiene a la proporción, esto ocurre cuando los datos son dicotómicos/binarios. Es decir: \\[\\bar{x}=\\hat{P}_a=\\frac{\\sum_s x_i}{n}=\\frac{\\#a}{n}\\] \\[\\hat{P} \\sim N\\left(P,\\frac{\\sigma_p^2}{n}\\right)=N\\left(P,\\frac{P(1-P)}{n}\\right)\\] \\[\\sigma^2_p=\\frac{\\sum_U x_i^2}{N}-\\mu^2=\\frac{\\sum_U x_i}{N}-P^2=P-P^2=P(1-P)\\] La proporción mide la participación de una característica dentro de la población/muestra. Por ejemplo Proporción de mujeres \\[P_{m}=\\frac{14}{24}=0.58 \\rightarrow 58\\%\\] Proporción de hombres \\[P_{h}=\\frac{10}{24}=0.42 \\rightarrow 42\\%\\] De esta forma, el intervalo de confianza para la proporción queda de la forma: \\[IC_{1-\\alpha}(P): \\hat{P} \\pm z_{\\alpha/2} *\\sqrt{\\frac{\\hat{P}(1-\\hat{P})}{n}}\\] Ejemplo: Se toma una muestra aleatoria de 35 cachorros y sobre este grupo se evidencia que 23 de ellos cuentan con sus vacunas respectivas. Calcule un intervalo de confianza al 95% para la proporción de cachorros sin vacunas. Si la muestra fue obtenida de un albergue de 200 cachorros, ¿cuál será el intervalo de confianza para el total de cachorros sin vacunas.? Solución, como información \\(n=35\\), \\(N=200\\), 23 tienen vacunas. \\[\\hat{P}_{sv}=\\frac{12}{35}\\] \\[IC_{1-\\alpha}(P):\\frac{12}{35} \\pm 1.96 *\\sqrt{\\frac{\\frac{12}{35}*\\frac{23}{35}}{35}}=0.34 \\pm 0.16\\] \\[IC_{95\\%}(P): [0.18 \\quad 0.5] \\rightarrow (\\%)[18 \\quad 50]\\] Una ventaja de la proporción es que se encuentra en unidades relativas, para expandir sus resultados a una población mayor bastara con multiplicar por el tamaño de la población. \\[IC_{95\\%}(T=P*N): 200*([0.18 \\quad 0.5]) \\rightarrow [36 \\quad 100]\\] Ejercicio Se realizó la toma de muestra de 45 palomas de la plaza Murillo un día cualquiera, se identificó a 31 palomas con alguna dificultad/dolencia en alguna de sus patas. Calcular el intervalo de confianza al 95% de confiabilidad para la proporción de palomas con problemas en alguna de sus patas. Si suponemos que la población de palomas alrededor de la plaza Murillo ronda las 7000 palomas, ¿cuál será el intervalo de confianza al 95% de confiabilidad del total de palomas sin problemas en sus patas? Solución, \\(n=45\\) 31 palomas con dificultades en sus patas, 14 palomas sin dificultades. \\[\\hat{P}_{cd}=\\frac{31}{45}=0.69; \\quad \\hat{P}_{sd}=\\frac{14}{45}=0.31\\] \\[IC_{1-\\alpha}(P_{cd}): 0.69 \\pm 1.96 *\\sqrt{\\frac{0.69*0.31}{45}}=0.69\\pm 0.14=\\] \\[IC_{95\\%}(P_{cd}): [0.55 \\quad 0.83]\\rightarrow (\\%)[55 \\quad 83]\\] \\[IC_{1-\\alpha}(P_{sd}): 0.31 \\pm 1.96 *\\sqrt{\\frac{0.69*0.31}{45}}=0.31\\pm 0.14=\\] \\[IC_{95\\%}(T_{sd}=N*P_{sd}):7000( [0.17 \\quad 0.45]) \\rightarrow [1190 \\quad 3150]\\] 4.6 pruebas de hipótesis El principal objetivo de la inferencia estadística es aproximarse al valor del parámetro \\(\\theta\\) de la población (\\(U\\)), mediante un estimador \\(\\hat{\\theta}\\) que viene definido por una muestra aleatoria (\\(s\\)). Las estrategias de estimación vistas hasta ahora son: Estimación puntual: \\[\\mu=\\frac{\\sum_U x_i}{N} \\rightarrow \\bar{x}=\\frac{\\sum_s x_i}{n}\\] Estimación por intervalo de confianza \\[IC_{1-\\alpha}(\\mu): \\bar{x}\\pm z_{\\alpha/2}\\sqrt{\\frac{\\hat{S}^2}{n}}\\] Ahora veremos las pruebas de hipótesis estadísticas, estas pruebas partes de una conjetura nuestra al rededor del parámetro de interés y esta conjetura es verificada mediante la información de la muestra. Cuando se elabora una hipótesis estadística se debe plantear 2 elementos; la hipótesis que se plantea (hipótesis nula) y el complemento de esta hipótesis planteada se denomina hipótesis alternativa. Ejemplo \\[H_0: \\theta = k\\] \\[H_1: \\theta \\neq k\\] \\[H_1: \\theta &gt; k\\] \\[H_1: \\theta &lt; k\\] Ejemplo, se observa a los estudiantes inscritos en la materia de estadística mediante una muestra de 10 estudiantes. Si la variable de interés es la estatura en centímetros \\[H_0: \\mu = 165\\] \\[H_1: \\mu&lt; 165\\] La manera de verificar la hipótesis planteada pasara por estudiar una muestra aleatoria, sobre la cual se pueda establecer una regla que nos permita decidir si la hipótesis es correcta o no. Normalmente se inicia calculando un estadístico de prueba que nos permitirá decidir con base a una regla definida en una región de aceptación. Al momento de tomar una decisión con base al estadístico de prueba y las regiones de aceptación y rechazo empleando la información de la muestra, es posible cometer errores dado el resultado real en \\(U\\). En las pruebas de hipótesis existen dos tipos de errores, el error de tipo I y el error de tipo II: Error de tipo I: (\\(\\alpha\\)) también conocido como un falso positivo. Rechazar algo verdadero Error de tipo II: (\\(\\beta\\)) también conocido como falso negativo. Aceptando algo falso 4.6.1 Pasos para una prueba de hipótesis Establecer la hipótesis nula (\\(H_0\\)) y la hipótesis alternativa (\\(H_1\\), \\(H_A\\)). La \\(H_A\\) puede ser de dos o una cola Definir el nivel de significancia \\(\\alpha\\). (el tamaño de la región de rechazo) Recolectar los datos de la muestra y calcular el estadístico de prueba (\\(Z\\)). Comparar el estadístico de prueba según las regiones críticas, esto es, la región de aceptación y la región de rechazo + \\(Z \\in RA \\rightarrow \\sim RH_0 (AH_0)\\) + \\(Z \\notin RA \\rightarrow RH_0\\) Calcular el P-valor. La probabilidad que la hipótesis nula sea verdadera. Tradicionalmente: + \\(P-valor&gt;\\alpha \\rightarrow \\sim RH_0 (AH_0)\\) + \\(P-valor&lt;\\alpha \\rightarrow RH_0\\) Calcular el intervalo de confianza del parámetro de estudio Realizar las conclusiones respectivas y analizar los resultados. 4.6.2 Prueba de hipótesis para la media Vamos a suponer que los datos de interés se distribuyen como una normal o al menos que el tamaño de muestra (\\(n\\)), de la muestra aleatoria para el estadístico de prueba es grande. Por lo tanto es posible utilizar el teorema del limite central. Existen dos variaciones de la prueba de hipótesis sobre la media; cuando se conoce la varianza y cuando no se conoce la varianza de los datos (\\(\\sigma^2\\)). 4.6.2.1 Con varianza \\(\\sigma^2\\) conocida Hipótesis \\[H_0: \\mu=\\mu_0\\] \\[H_A: \\mu \\neq \\mu_0\\] 2. Nivel de significancia: Este es \\(\\alpha\\) y el tipo de prueba dado la \\(H_A\\) es bilateral o de dos colas, esto significa que existen dos regiones de rechazo, cada región de tamaño \\(\\alpha/2\\) 3. Estadístico de prueba: Se cuenta con una muestra aleatoria (\\(X_1,X_2,\\ldots,X_n\\)) estas son independientes e idénticamente distribuidas. La estadística de prueba es: \\[Z_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\\] Si la hipótesis nula es cierta entonces se puede garantizar que \\(Z_0\\sim N(0,1)\\), esto significa que: \\[E[\\bar{x}]=\\mu=\\mu_0\\] 4. Regiones de aceptación y rechazo: dependen del nivel de significancia \\(\\alpha\\) # alpha=0.1 (10%) curve(dnorm(x),xlim = c(-4,4),main=&quot;Significancia al 10%&quot;) abline(v=c(-1.64,1.64),col=&quot;red&quot;,lty=2) text(c(-3.5,0,3.5),rep(0.2,3),c(&quot;Rechazo&quot;,&quot;Aceptación&quot;,&quot;Rechazo&quot;)) # alpha=0.05 (5%) curve(dnorm(x),xlim = c(-4,4),main=&quot;Significancia al 5%&quot;) abline(v=c(-1.96,1.96),col=&quot;red&quot;,lty=2) text(c(-3.5,0,3.5),rep(0.2,3),c(&quot;Rechazo&quot;,&quot;Aceptación&quot;,&quot;Rechazo&quot;)) # alpha=0.01 (1%) curve(dnorm(x),xlim = c(-4,4),main=&quot;Significancia al 1%&quot;) abline(v=c(-2.58,2.58),col=&quot;red&quot;,lty=2) text(c(-3.5,0,3.5),rep(0.2,3),c(&quot;Rechazo&quot;,&quot;Aceptación&quot;,&quot;Rechazo&quot;)) La decisión; Se rechaza la \\(H_0\\) cuando: \\[Z_0&gt; Z_{\\alpha/2} \\quad ó \\quad Z_0&lt; -Z_{\\alpha/2}\\] Los valores más usuales para el \\(Z_{\\alpha/2}\\) son: al 10% de significancia \\(Z_{\\alpha/2}=Z_{0.05}=1.64\\) al 5% de significancia \\(Z_{\\alpha/2}=Z_{0.025}=1.96\\) al 1% de significancia \\(Z_{\\alpha/2}=Z_{0.005}=2.58\\) Ejercicio, se tiene un curso de estadística con su evaluación final sobre 100 puntos, se sabe por información pasada que la desviación estándar es alrededor de 10 pts. Se debe probar la hipótesis que el grupo tiene una nota promedio de 65 pts, tomar un nivel de significancia del 5%. Para realizar la prueba se obtuvo una muestra de 20 estudiantes, con las siguientes mediciones: set.seed(905) x&lt;-round(runif(20,45,75)) x ## [1] 75 72 56 47 64 63 64 66 51 67 75 51 53 69 ## [15] 66 57 70 63 51 50 \\[H_0: \\mu= 65\\] \\[H_A: \\mu\\neq 65\\] \\[Z_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}=\\frac{61.5-65}{\\frac{10}{\\sqrt{20}}}=-1.565\\] La decisión, si se cumple alguna de las siguientes desigualdades se rechaza la hipótesis nula: \\[-1.565&gt; 1.96 (F) \\quad ó \\quad -1.565&lt; -1.96 (F)\\] Por lo tanto, no se rechaza la hipótesis nula. De manera gráfica: # alpha=0.05 (5%) curve(dnorm(x),xlim = c(-4,4),main=&quot;Significancia al 5%&quot;) abline(v=c(-1.96,1.96),col=&quot;red&quot;,lty=2) text(c(-3.5,0,3.5),rep(0.2,3),c(&quot;Rechazo&quot;,&quot;Aceptación&quot;,&quot;Rechazo&quot;)) abline(v=-1.565,col=&quot;blue&quot;,lty=3) text(x=-1.565,y=0.05,&quot;Z0&quot;) 4.6.2.1.1 Para pruebas unilaterales Se utiliza el mismo estadístico de prueba \\(Z_0\\), lo que se modifica son las regiones críticas. \\[H_A: \\mu&gt;\\mu_0\\] Se rechaza \\(H_0\\) si: \\[Z_0&gt;Z_{\\alpha}\\] En el otro caso: \\[H_A: \\mu&lt;\\mu_0\\] Se rechaza \\(H_0\\) si: \\[Z_0&lt; -Z_{\\alpha}\\] Los valores mas usuales de \\(Z_\\alpha\\) para pruebas unilaterales son: 10% \\(Z_{0.1}=1.28\\) 5% \\(Z_{0.05}=1.64\\) 1% \\(Z_{0.01}=2.33\\) # &quot;&lt;&quot; curve(dnorm(x),xlim = c(-4,4),main=&quot;Pruebas unilaterales &lt;&quot;) abline(v=c(-1.28,-1.64,-2.33),col=&quot;red&quot;,lty=2) text(c(-3.5,2),rep(0.2,2),c(&quot;Rechazo&quot;,&quot;Aceptación&quot;)) text(c(-1.28,-1.64,-2.33),y=0.3,c(&quot;10%&quot;,&quot;5%&quot;,&quot;1%&quot;),cex=0.8) # &quot;&gt;&quot; curve(dnorm(x),xlim = c(-4,4),main=&quot;Pruebas unilaterales &gt;&quot;) abline(v=c(1.28,1.64,2.33),col=&quot;red&quot;,lty=2) text(c(-2,3.5),rep(0.2,2),c(&quot;Aceptación&quot;,&quot;Rechazo&quot;)) text((-1)*c(-1.28,-1.64,-2.33),y=0.3,c(&quot;10%&quot;,&quot;5%&quot;,&quot;1%&quot;),cex=0.8) 4.6.2.2 Con varianza desconocida Si el tamaño de muestra es mayor a 30, todo lo visto anteriormente se mantiene, el único cambio se da en el estadístico de prueba, donde en lugar de \\(\\sigma\\) se toma la variabilidad muestral (\\(\\hat{S}\\)). Es decir: \\[\\sigma^2=\\frac{\\sum_U (x_i-\\mu)^2}{N}\\] \\[\\hat{S}^2=\\frac{\\sum_s (x_i-\\bar{x})^2}{n-1}\\] Esto implica que: \\[Z_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\hat{S}}{\\sqrt{n}}}\\] Si la muestra no es mayor a 30, podemos hacer un supuesto de normalidad y la aproximación para las regiones críticas se la trabaja con la distribución \\(t-student\\) curve(dnorm(x),xlim=c(-4,4),lwd=2) for(i in 1:30){ curve(dt(x,i),xlim=c(-4,4),lty=2,col=&quot;red&quot;,add=T) } Hasta ahora se tienen 3 casos para la prueba de hipótesis sobre la media. \\[H_0: \\mu=\\mu_0\\] Cuando la varianza es conocida, se utiliza la distribución normal y el estadístico de prueba es: \\[Z_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\sigma}{\\sqrt{n}}}\\] \\[Z_0\\sim N(0,1)\\] Para: \\[H_A: \\mu \\neq\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[Z_0 &lt; -Z_{\\alpha/2}\\quad ó \\quad Z_0 &gt; Z_{\\alpha/2}\\] \\[H_A: \\mu &lt;\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[Z_0 &lt; -Z_{\\alpha}\\] \\[H_A: \\mu &gt;\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[Z_0 &gt; Z_{\\alpha}\\] Cuando la varianza es desconocida y la muestra es mayor a 30, se utiliza la distribución normal y el estadístico de prueba es: \\[Z_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\hat{S}}{\\sqrt{n}}}\\] \\[Z_0\\sim N(0,1)\\] Para: \\[H_A: \\mu \\neq\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[Z_0 &lt; -Z_{\\alpha/2}\\quad ó \\quad Z_0 &gt; Z_{\\alpha/2}\\] \\[H_A: \\mu &lt;\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[Z_0 &lt; -Z_{\\alpha}\\] \\[H_A: \\mu &gt;\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[Z_0 &gt; Z_{\\alpha}\\] Cuando la varianza es desconocida y la muestra es menor o igual a 30, se utiliza la distribución t-student y el estadístico de prueba es: \\[t_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\hat{S}}{\\sqrt{n}}}\\] \\[t_0\\sim t(v=n-1)\\] Para: \\[H_A: \\mu \\neq\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[t_0 &lt; -t_{\\alpha/2,n-1}\\quad ó \\quad t_0 &gt; t_{\\alpha/2,n-1}\\] \\[H_A: \\mu &lt;\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[t_0 &lt; -t_{\\alpha,n-1}\\] \\[H_A: \\mu &gt;\\mu_0\\] Se rechaza la \\(H_0\\) cuando: \\[t_0 &gt; t_{\\alpha,n-1}\\] Ejemplo, Se tiene el peso en kilogramos de una muestra aleatoria de tamaño 5 de un determinado animal, estos datos son: 4.5, 6.7, 5.0, 4.0 y 6.1. Se piensa que estos animales tienen problemas de nutrición y se busca verificar esto mediante la muestra recolectada. Se acepta que existen problemas de nutrición si el peso es inferior a 4.2 kg. Realice la prueba de hipótesis correspondiente para verificar esto. Solución, \\[H_0: \\mu=4.2 \\quad ; \\quad H_A: \\mu&lt;4.2\\] \\[t_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\hat{S}}{\\sqrt{n}}}=\\frac{5.26-4.2}{\\frac{1.12}{\\sqrt{5}}}=2.12\\] (Vamos a utilizar un nivel de significancia del 5%) Se rechaza la \\(H_0\\) cuando la siguiente desigualdad se cumpla: \\[2.12 &lt; -t_{0.05,4}=-2.1318\\] Por lo tanto, como no se cumple la desigualdad, se concluye que no existe evidencia estadística suficiente para rechazar la hipótesis nula. Esto implica que posiblemente la población de animales estudiados no tengan problemas de nutrición. Ejercicio, Se considera que un determinado fruto esta maduro cuando su árbol supera la altura de 175 centímetros, para verificar si ya se puede cosechar la fruta se toma una muestra aleatoria de 7 árboles, teniendo los siguientes resultados: 140, 200, 178, 167, 170, 180, 192. ¿Será que ya se puede realizar la cosecha? Solución, \\[H_0: \\mu=175 \\quad ; \\quad H_A: \\mu&gt;175\\] \\[t_0=\\frac{\\bar{x}-\\mu_0}{\\frac{\\hat{S}}{\\sqrt{n}}}=\\frac{175.29-175}{\\frac{19.41}{\\sqrt{7}}}=0.0395\\] Se rechaza la \\(H_0\\) cuando se cumple la siguiente desigualdad: \\[t_0 &gt; t_{0.05,6}\\] Suponiendo un \\(\\alpha=0.05\\) (5%) \\[0.0395 &gt; 1.9432 (F)\\] Por lo tanto, como la desigualdad no se cumple; no es posible rechazar la hipótesis nula, esto implica que no se recomienda iniciar con la cosecha. 4.6.3 Tamaño de muestra a partir del margen de error Recordar el intervalo de confianza de la media: \\[\\bar{x} \\pm z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\quad ; \\quad \\bar{x} \\pm \\epsilon\\] Imaginemos que queremos controlar el ancho del intervalo de confianza, a ese ancho lo vamos a denominar margen de error (\\(\\epsilon\\)), entonces: \\[\\epsilon=z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\] Ahora, es posible delimitar a priori el margen de error, el nivel de confiabilidad y aproximar \\(\\sigma\\) con base a un estudio pasado o una prueba piloto. De esta forma es posible tener una formula para el tamaño de muestra \\(n\\), en función de \\(\\epsilon\\), \\(z_{\\alpha/2}\\) y \\(\\sigma\\). Esta es: \\[n=\\left(\\frac{z_{\\alpha/2}* \\sigma}{\\epsilon}\\right)^2\\approx \\left(\\frac{z_{\\alpha/2}* \\hat{\\sigma}}{\\epsilon}\\right)^2\\] Ejemplo, para el caso de los árboles y la cosecha, calcular el tamaño de muestra necesario si se fija un margen de error de 5 cm, un nivel de confiabilidad del 95%, usar como aproximación de \\(\\sigma\\) el dato de los 7 árboles. \\[n= \\left(\\frac{z_{\\alpha/2}* \\hat{\\sigma}}{\\epsilon}\\right)^2=\\left(\\frac{1.96* 19.41}{5}\\right)^2=57.89\\approx58\\] 4.6.4 Tamaño de muestra a partir de los errores de tipo I y II Cuando se trabaja con tamaños de muestra basados en los errores de tipo I y II, se debe predefinir 3 aspectos: El tamaño del error de tipo I: \\(\\alpha\\), \\(0.01, 0.05, 0.1\\) El tamaño del error de tipo II: \\(\\beta\\), \\(0.1, 0.2\\) Efecto de tamaño: \\[\\delta=|\\mu_0-\\mu_A|\\] \\[n=\\left[\\frac{\\hat{\\sigma} *(z_{\\alpha}+z_\\beta)}{\\delta}\\right]^2=\\frac{\\hat{\\sigma}^2 *(z_{\\alpha}+z_\\beta)^2}{\\delta^2}\\] Los valores más comunes: \\(z_{\\alpha=0.05}=1.64\\) \\(z_{\\alpha=0.01}=2.33\\) \\(z_{\\alpha=0.1}=1.28\\) \\(z_{\\beta=0.1}=1.28\\) \\(z_{\\beta=0.2}=0.84\\) Ejemplo ¿Cuán grande debe ser el tamaño de muestra si de define un nivel de significancia del 5%, un error de tipo II del 10%, debiendo detectar una diferencia al promedio de al menos 1. Teniendo una varianza de 1.57. Solución, \\(\\delta=1\\) \\[n=\\frac{\\hat{\\sigma}^2 *(z_{\\alpha}+z_\\beta)^2}{\\delta^2}=\\frac{1.57 *(1.64+1.28)^2}{1}=13.38\\approx 14\\] Ejercicio Para el ejemplo de los árboles, se sabe que \\(\\hat{\\sigma}=19.41\\), si se quiere obtener el tamaño de muestra necesario tomando en cuenta una distancia mínima de 5 centímetros. Calcular el tamaño de muestra necesario, tomar un \\(\\alpha\\) del 5% y un \\(\\beta\\) del 20%. \\[n=\\left[\\frac{\\hat{\\sigma} *(z_{\\alpha}+z_\\beta)}{\\delta}\\right]^2=\\left[\\frac{19.41 *(1.64+0.84)}{5}\\right]^2=92.69\\approx 93\\] \\(z_{\\alpha=0.05}=1.64\\) \\(z_{\\alpha=0.01}=2.33\\) \\(z_{\\alpha=0.1}=1.28\\) \\(z_{\\beta=0.1}=1.28\\) \\(z_{\\beta=0.2}=0.84\\) \\[n=\\left[\\frac{(z_{\\alpha}+z_\\beta)}{\\frac{\\delta}{\\hat{\\sigma}}}\\right]^2\\] \\[EMD=\\frac{\\delta}{\\hat{\\sigma}}=\\frac{|\\mu_0-\\mu_A|}{\\hat{\\sigma}}\\] Se conoce como el efecto mínimo detectable, que mide la diferencia entre en términos de desviaciones estándar. Existen valores sugeridos para este EMD, varían de 0.15 a 0.25. "],["relación-entre-dos-más-variables.html", "5 Relación entre dos más variables 5.1 Correlación versus Causalidad 5.2 Covarianza y Correlación 5.3 Relación entre variables cualitativas", " 5 Relación entre dos más variables Hasta el tema 3 todo el análisis estaba concentrado en el estudio de una sola variable, sus características, como resumirle, como aproximarla mediante una muestra aleatoria. En esta apartado ahora se estudiara el comportamiento simultaneo de 2 o más variables. La importancia de estudiar el comportamiento de dos o más variables radica en que las unidades de análisis son unidades que presentan múltiples características y comprender como estas se relacionan ayuda a un mejor análisis estadístico. Existen varios métodos que permiten enteder la relación que existe entre las variables, desde métodos muy simples que solo describen la relación, hasta métodos más complejos que permiten predecir el comportamiento de una variable usando a otra. Alguno de estos métodos son: Correlación o covarianza: Permite medir la relación (lineal) entre 2 variables cuantitativas Tablas de contigencia (test de independencia, chi-cuadrado): Permite medir la relación entre 2 variables cualitativas, es posible trabajar con una relación mixta (cuanti-cuali) Diseño experimental: Plantea identificar el efecto causal de una variable sobre otro, mediante la realización de un experimento basado en asignaciones aleatorias. Regresiones: es un método que permite entender como una variable \\(Y\\) es afectada por otras variables \\(X_1,X_2, \\ldots\\). Regresión simple (2 variables) (Y cuanti, X mixta) Regresión múltiple (2 o más variables) (Y cuanti, X mixta) Regresión de respuesta binaria: Probit, Logit (Y binaria, X Mixtas) Regresión de respuesta discreta: Poisson (Y discreta, X mixta) Regresión multinivel. Métodos multivariantes (Minería de datos/Machine learning) Reducción de variables, componentes principales Agrupamiento Clasificación Minería de texto Regresión 5.1 Correlación versus Causalidad Diferencia entre correlación y causalidad Correlación no implica causalidad La causalidad busca entender de forma clara la causa y efecto entre dos variables \\(X\\rightarrow Y \\leftarrow Z \\leftarrow W\\) Métodos estadísticos para identificar la causalidad Diseños experimentales: Poblaciones altamente controladas (laboratorio) Diseños cuasi-experimentales: No cuenta con mucho control sobre la población de interés Diferencia en diferencia Regresión discontinua Variables instrumentales Emparejamiento Métodos estructurales. (Modelar la varianza de los datos) Ejemplos de interés sobre causalidad en Biología Dietas sobre animales, hábitos basados en juegos Tratamiento vinculado a cultivos. (Fertilizantes, tipo de riego, variedad del cultivo, etc) 5.2 Covarianza y Correlación Estas dos medidas son exclusivas cuando las variables de interés son ambas cuantitativas, la covarianza es una medida que mantiene las unidades de medida de los datos, mientras que la correlación es una medida relativa, es decir, carece de unidades de medida y también es acotada ya que se mueve entre -1 y 1. Sean las variables \\(X\\) e \\(Y\\), ambas variables cuantitativas (continuas o discretas), la covarianza en la población de interés se define como: \\[\\sigma_{xy}=\\frac{\\sum_U(x_i-\\mu_{x})(y_i-\\mu_{y})}{N}\\] Como casi siempre se trabaja con muestras aleatorias, la covarianza muestral esta dada por: \\[S_{xy}=\\frac{\\sum_s(x_i-\\bar{x})(y_i-\\bar{y})}{n-1}\\] Para la interpretación de la covarianza, notar que esta puede tomar valores positivos y negativos, en cuanto al valor que se obtenga, este depende de la naturaleza de los datos. La interpretación del valor de la covarianza no es tan útil, lo que que normalmente es su signo y cuando alcanza el cero: \\(S_{xy}&gt;0\\): Esto implica que existe una relación directa, es decir, mientras una variable crece la otra también crece, una baja la otra también baja. Ej. La edad con la estatura hasta los 25 años. \\(S_{xy}&lt;0\\): La relación es opuesta/inversa, mientras una sube la otra baja y viceversa. La edad con la estatura a partir de una edad adulta mayor. \\(S_{xy}=0\\): No existe una relación lineal Una medida más útil es la correlación, esta se define para la población como: \\[r=\\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y}\\] Para la muestra: \\[\\rho=\\frac{S_{xy}}{S_x S_y}\\] La interpretación respecto el signo, mantiene la idea de la covarianza. Pero ahora se puede interpretar el valor: \\(\\rho \\rightarrow 1\\) que la relación directa es muy fuerte \\(\\rho \\rightarrow -1\\) que la relación inversa es muy fuerte \\(\\rho \\rightarrow 0\\) existe una fuerte sospecha de independencia lineal (no existe relación lineal) 5.3 Relación entre variables cualitativas Cuando ambas variables son cualitativas nominales En este caso se puede usar el coeficiente Chi-cuadrado: \\[\\chi^2 = \\sum_{i=1}^p\\sum_{j=1}^q \\frac{\\left(n_{ij}-\\frac{n_{x_i}n_{y_j}}{n}\\right)^2}{\\frac{n_{x_i}n_{y_j}}{n}}=\\sum_{fc}\\frac{(O-E)^2}{E}\\] Se debe construir una tabla de contingencia. El valor que se obtenga no es muy útil para la interpretación, principalmente nos sirve para saber o sospechar de la no existencia de relación, esto sucede cuando el valor es cercano a 0. Sin embargo, una alternativa para interpretar el valor es el coeficiente de contingencia, que tiene la forma de: \\[C = \\sqrt{\\frac{\\chi^2}{\\chi^2+n}}\\] Este coeficiente se define en: \\[0\\leq C &lt; 1\\] Donde si C es más cercano a 0 implica una falta de relación entre las variables y si es más cercano a 1 implica una relación fuerte. En realidad el máximo valor que puede alcanzar C es: \\[C_{max}=\\sqrt{\\frac{k-1}{k}}, \\quad k=min(\\#filas, \\# columnas)\\] Tarea para el examen, Sperman-Ordinal \\[r_s = 1-\\frac{6\\sum_s d_i^2}{n(n^2-1)}\\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
