---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Muestreo y estimaciones

## Conceptos 

  - **Población (universo)** ($U$): La colección completa de los elementos de interés.
  - **Muestra** ($s$): Un subcobjunto de la población de interés o el universo.
  
$$s \subset U$$

  - **Muestreo**: El mecanismo utilizado para extraer la muestra del universo, en la estadística se valora principalmente a un **mecanismo aleatorio**, esto debido a las propiedades que este genera (*Muestra valida estadísticamente*).
  - **Inferencia**: Es un área de la estadística que busca a partir de una muestra estadísticamente valida *describir* a la población de estudio. Mediante la inferencia descriptiva, inferencia predictiva y la inferencia causal. 
  - **Parámetro**: Una función sobre la población
  
$$\theta=f(U,X)$$

  - **Estadística:** Una función sobre la muestra
  
$$Estadística=f(s,X)$$

  - **Estimador**: Es una estadística, que tiene el objetivo de aproximar a un parámetro
  
$$\hat{\theta}=f(s,X)$$
  
Ejemplo.

En una población de estudiantes de tamaño $N=10$, se tiene el gasto en transporte a la universidad en un día común. Se extrae una muestra de tamaño 4, proponer estimadores para el total del gasto en transporte.


```{r}
x<-c(2,4,5,5,2,10,15,7,4,2)
sum(x)#parámetro del total

s<-sample(x,4)
s<-c(5,5,2,7)

s2<-sample(x,4)
s2<-c(10,5,5,15)
```

$$\hat{\theta}_1=\sum_s x_i+n*N =5+5+2+7+40=\{59,75\}$$

$$\hat{\theta}_2=n\sum_{s,<>}x_i=(5+2+7)*4=\{56,120\}$$

$$\hat{\theta}_3=\frac{1}{x_{max}}\prod_s x_i= \frac{5*5*2*7}{7}=\{50,250\}$$
$$\hat{\theta}_4=\frac{N\sum_s x_i}{n}=N*\bar{x}=\frac{10*(5+5+2+7)}{4}=\{47.5,87.5\}$$

> ¿Cuántas muestras posibles se pueden construir en el ejercicio anterior?

Si las muestras son sin reposición la cantidad de muestras posibles es determinada por:

$$NCn=10C4=\frac{10!}{6!*4!}=210$$

```{r}
combn(x,4)
choose(10,4)
format(choose(800,20),scientific = F)
```

## Distribuciones muestrales

Es la forma o el comportamiento de las muestras posibles respecto algún estimador, su importancia se debe a la posibilidad de estudiar el fenómeno completo e identificar patrones.

```{r}
ss<-combn(x,4)
t1<-apply(ss,2,sum)+4*10
t2<-sapply(apply(ss,2,unique), sum)*4
t3<-apply(ss,2,prod)/apply(ss,2,max)
t4<-apply(ss,2,mean)*10
tt<-cbind(t1,t2,t3,t4)
#representante
apply(tt,2,mean)
#variabilidad
apply(tt,2,sd)
#gráfica
par(mfrow=c(2,2))
hist(t1,xlim=c(0,100));hist(t2,xlim=c(0,100));hist(t3,xlim=c(0,100));hist(t4,xlim=c(0,100))
boxplot(t1);boxplot(t2);boxplot(t3);boxplot(t4)
plot(density(t1));abline(v=56);plot(density(t2));abline(v=56);plot(density(t3));abline(v=56);plot(density(t4));abline(v=56)
```

Los estimadores $\hat{\theta}$ finalmente son variables aleatorias ya que a priori no sabemos el resultado antes de sacar la muestra respectiva. Cuyo recorrido de esta variable aleatoria es dada por los distintos valores que obtienen de las muestras posibles. 

Existen dos criterios prácticos para calificar la calidad de un estimador:

  * Estimador insesgado (más relevante): Se refiere a que el centro de la distribución es el parámetro de interés, de manera formal:

$$E[\hat{\theta}]=\theta$$  
  
  * Estimador eficiente: La idea de eficiencia en los estimadores se mide con la varianza del estimador, el estimador con menor varianza es el más eficiente. Por ejemplo:

  
$$V(\hat{\theta}_1)>V(\hat{\theta}_2)$$  
  
$\hat{\theta}_2$ es más eficiente que $\hat{\theta}_1$

Existen estimadores clásicos y frecuentemente usados que son estimadores insesgados, entre ellos:

### Media

  * Parámetro
  
$$\mu_x=\frac{\sum_U x_i}{N}$$

  * Estimador (media muestral)

$$\bar{x}=\frac{\sum_s x_i}{n}$$

### Diferencia de medias

Es una medida que compara dos poblaciones

  * Parámetro
  
$$\mu_1-\mu_2=\frac{\sum_{U_1} x_i}{N_1}-\frac{\sum_{U_2} x_i}{N_2}$$

  * Estimador (medias muestrales)
  
$$\bar{x}_1-\bar{x}_2=\frac{\sum_{s_1} x_i}{n_1}-\frac{\sum_{s_2} x_i}{n_2}$$
### Total

  * Parámetro
  
$$t_x=\sum_U x_i$$

  * Estimador 

$$\hat{t}_x=N*\frac{\sum_s x_i}{n}=N*\bar{x}$$

### Proporción 

Es una medida que identifica la proporción de participación de alguna característica de interés


  * Parámetro
  
$$P_A=\frac{\#A}{N}=\frac{\sum_U x_i}{N}; \quad \{x_i=1 \quad i \in A, x_i=0 \quad  eoc\}$$

  * Estimador
  
$$\hat{P}_A=\frac{\#a}{n}=\frac{\sum_s x_i}{n}; \quad \{x_i=1 \quad i \in A, x_i=0 \quad  eoc\}$$

## Teorema del limite central

Si $\bar{x}$ es la media muestral de una muestra aleatoria de tamaño $n$ tomada de una población $U$ con media poblacional $\mu_x$ y varianza finita (se puede calcular)  $\sigma_x^2$. Entonces la forma limite de la **distribución** de $\bar{x}$ a medida que $n\rightarrow \infty$ **crece**, se puede asegurar:

$$\bar{x}\sim N\left(\mu=\mu_x,\sigma^2=\frac{\sigma^2_x}{n}\right)$$

Nota: Esta idea de $n$ grande, en estadística tradicionalmente se toma como "grande" cuando $n\geq 30$, hay textos que plantean $n\geq 20$.

Ejemplo:

Recordar la idea de una distribución muestral:

```{r}
x<-c(2,4,5,5,2,10,15,7,4,2)
n<-4
choose(10,4)
ss<-combn(x,4)
ss
#distribución de la media
mm<-apply(ss,2,mean)
mm
hist(mm)
mean(x) #parámetro media poblacional
mean(mm) # Insesgadez
```

Vamos a **simular** el teorema del limite central.

Imaginar que se tiene una población de 500 gatos y se quiere observar el peso en kilogramos.

```{r}
N<-500
set.seed(855)
xx<-rnorm(N, 4,1.2)
xx<-round(xx,1)
xx
n<-40
format(choose(N,n),scientific = F)# muestras posibles
```

Como no es posible estudiar a todas las muestras posibles, debido a una limitación computacional se va a obtener y estudiar una parte de estas distribuciones muestrales.

```{r}
k<-1000 # parte de las muestras posibles
mm<-NULL
for(i in 1:k){
  maux<-sample(xx,n)
  mm[i]<-mean(maux)  
}
mm
hist(mm,xlim = c(3,5))
abline(v=mean(xx),col="red",lwd=2)

vx<-sum((xx-mean(xx))^2)/N
# la distribución teórica
curve(dnorm(x,mean(xx),sqrt(vx/n)),xlim = c(3,5))

# de forma gráfica
hist(mm,xlim = c(3,5),freq = F)
curve(dnorm(x,mean(xx),sqrt(vx/n)),add=T,col="red",lwd=2)
```

> Nota: El teorema del limite central supone poblaciones grandes ("infinitas")

> Nota: Cuando las poblaciones son pequeñas el teorema del limite central se puede seguir usando, sin embargo, la convergencia a la normalidad no estan fina

## Distribución muestral de la media para muestras de 30 o más

Sea $\bar{x}$ la media muestral un estimador para la media poblacional $\mu_x$.

A partir del teorema de limite central y tomando en cuenta $n\geq 30$. Se puede definir a su distribución muestral como:

$$\bar{X} \sim N\left(\mu_x,\frac{\sigma_x^2}{n}\right)\approx N\left(\bar{x},\frac{s^2}{n} \right)$$

De manera general para la distribución de la media muestral podemos mencionar lo siguiente:

  * Es un estimador insesgado, de tal forma que $E[\bar{x}]=\mu$
  * La variabilidad de la media muestra es:
  
$$V(\bar{x})=\sigma^2_{\bar{x}}=\frac{\sigma^2}{n}$$  

  * La estimación de la varianza viene dada por:

$$s^2_{\bar{x}}=\frac{s^2}{n}$$
  
Este último resultado también se denomina el error estándar del estimador de la media cuando:

$$s_{\bar{x}}=\sqrt{\frac{s^2}{n}}=EE(\bar{x})$$

> Ejercicio 1: 

Se tiene el dato del peso medido en kg. de una muestra de 9 animales:

4.0, 4.3, 4.5, 4.6, 4.7, 4.8, 4.9, 4.9, 5.1.

Obtener la media muestral y el error estándar.

Solución:

$$\bar{x}=\frac{\sum_s x_i}{n}=\frac{41.8}{9}=4.64$$

Para el error estándar:

$$s^2=\frac{\sum_s (x_i-\bar{x})^2}{n-1}=0.1153$$

La varianza del estimador:

$$s^2_{\bar{x}}=\frac{0.1153}{9}=0.0128$$

Finalmente el error estándar es:

$$s_{\bar{x}}=\sqrt{0.0128}=0.1132$$

## Intervalo de confianza, límites de confianza

Una segunda forma de aproximarse al valor real de un parámetro poblacional, es mediante un intervalo de confianza que brinda limites en los que se encuentra el verdadero valor del parámetro a un nivel determinado de confiabilidad. En términos de probabilidades, el objetivo es determinar:

$$P(L<\theta<U)=1-\alpha=\text{Nivel de confiabilidad}$$
El valor $\alpha$ se conoce como la significancia y sus valores más usuales son de $0.01, 0.05,0.1$, que respectivamente representan el 99%, 95% y 90% de confiabilidad.

El objetivo ahora es determinar la forma de los límites $L=Lower$ y $U=Upper$, esto depende del estimador con el que se trabaje, para el estimador de la media, si usamos el teorema del límite central sabemos que:

$$\bar{X} \sim N\left(\mu_x,\frac{\sigma_x^2}{n}\right)$$
Ahora, si realizamos una transformación:

$$Z=\frac{\bar{X}-\mu_x}{\frac{\sigma_x}{\sqrt{n}}}\sim N(0,1)$$
Por ejemplo, para un $\alpha=0.05$

$$P(-z_{0.05/2}<Z<z_{0.05/2})=0.95 \quad(95\%)$$

De esta forma, el intervalo de confianza de la media es:

$$IC_{1-\alpha}(\mu): \bar{x} \pm z_{\alpha/2} *\frac{S}{\sqrt{n}}$$
> Nota: 

Esta formula se aplica usando las información de la muestra, en algunos casos es posible contar con la varianza original de los datos $\sigma^2$, si esto sucede la formula es:

$$IC_{1-\alpha}(\mu): \bar{x} \pm z_{\alpha/2} *\frac{\sigma}{\sqrt{n}}$$

Los valores más comunes para confiabilidad son:

  * 99% de confiabilidad: $z_{\alpha/2}=2.58$
  * 95% de confiabilidad: $z_{\alpha/2}=1.96$
  * 90% de confiabilidad: $z_{\alpha/2}=1.64$

> Ejercicio: (Capitulo 6, ejericio 6.)

El tiempo de incubación de huevos de lagarto fue medido para 24 lagartos. Estos 24 lagartos provienen de una población que tiene un 
$$\sigma^2=89.06 días^2$$
Y la media muestral
$$\bar{x}=61.4 días$$

  * Calcular el IC al 99% para la media de incubación
  * Calcular el IC al 95% para la media de incubación
  * Calcular el IC al 90% para la media de incubación

Solución

Al 99%,

$$IC_{1-\alpha}(\mu): 61.4 \pm 2.58 *\sqrt{\frac{89.06}{24}}=61.4 \pm 4.97=$$
$$IC_{99\%}(\mu): [56.43 \quad 66.37]$$

Al 95%,

$$IC_{1-\alpha}(\mu): 61.4 \pm 1.96 *\sqrt{\frac{89.06}{24}}=61.4 \pm 3.78=$$

$$IC_{95\%}(\mu): [57.62 \quad 65.18]$$

Al 90%,

$$IC_{1-\alpha}(\mu): 61.4 \pm 1.64 *\sqrt{\frac{89.06}{24}}=61.4 \pm 3.16=$$

$$IC_{90\%}(\mu): [58.24 \quad 64.56]$$

Como un caso particular de la media se tiene a la proporción, esto ocurre cuando los datos son dicotómicos/binarios. Es decir:

$$\bar{x}=\hat{P}_a=\frac{\sum_s x_i}{n}=\frac{\#a}{n}$$

$$\hat{P} \sim N\left(P,\frac{\sigma_p^2}{n}\right)=N\left(P,\frac{P(1-P)}{n}\right)$$

$$\sigma^2_p=\frac{\sum_U x_i^2}{N}-\mu^2=\frac{\sum_U x_i}{N}-P^2=P-P^2=P(1-P)$$

La proporción mide la participación de una característica dentro de la población/muestra. Por ejemplo

  * Proporción de mujeres

$$P_{m}=\frac{14}{24}=0.58 \rightarrow 58\%$$  
  
  * Proporción de hombres

$$P_{h}=\frac{10}{24}=0.42 \rightarrow 42\%$$

De esta forma, el intervalo de confianza para la proporción queda de la forma:

$$IC_{1-\alpha}(P): \hat{P} \pm z_{\alpha/2} *\sqrt{\frac{\hat{P}(1-\hat{P})}{n}}$$

> Ejemplo: 

Se toma una muestra aleatoria de 35 cachorros y sobre este grupo se evidencia que 23 de ellos cuentan con sus vacunas respectivas. Calcule un **intervalo de confianza** al 95% para la *proporción de cachorros sin vacunas*. Si la muestra fue obtenida de un albergue de 200 cachorros, ¿cuál será el intervalo de confianza para el **total de cachorros** sin vacunas.?

Solución, como información $n=35$, $N=200$, 23 tienen vacunas.

$$\hat{P}_{sv}=\frac{12}{35}$$

$$IC_{1-\alpha}(P):\frac{12}{35} \pm 1.96 *\sqrt{\frac{\frac{12}{35}*\frac{23}{35}}{35}}=0.34 \pm 0.16$$

$$IC_{95\%}(P): [0.18 \quad 0.5] \rightarrow (\%)[18 \quad 50]$$

Una ventaja de la proporción es que se encuentra en unidades relativas, para expandir sus resultados a una población mayor bastara con multiplicar por el tamaño de la población.

$$IC_{95\%}(T=P*N): 200*([0.18 \quad 0.5]) \rightarrow [36 \quad 100]$$

> Ejercicio

Se realizó la toma de muestra de 45 palomas de la plaza Murillo un día cualquiera, se identificó a 31 palomas con alguna dificultad/dolencia en alguna de sus patas. 

  * Calcular el intervalo de confianza al 95% de confiabilidad para la proporción de palomas con problemas en alguna de sus patas. 
  * Si suponemos que la población de palomas alrededor de la plaza Murillo ronda las 7000 palomas, ¿cuál será el intervalo de confianza al 95% de confiabilidad del total de palomas sin problemas en sus patas?

Solución, $n=45$ 31 palomas con dificultades en sus patas, 14 palomas sin dificultades.

$$\hat{P}_{cd}=\frac{31}{45}=0.69; \quad \hat{P}_{sd}=\frac{14}{45}=0.31$$

$$IC_{1-\alpha}(P_{cd}): 0.69 \pm 1.96 *\sqrt{\frac{0.69*0.31}{45}}=0.69\pm 0.14=$$
$$IC_{95\%}(P_{cd}): [0.55 \quad 0.83]\rightarrow (\%)[55 \quad 83]$$

$$IC_{1-\alpha}(P_{sd}): 0.31 \pm 1.96 *\sqrt{\frac{0.69*0.31}{45}}=0.31\pm 0.14=$$

$$IC_{95\%}(T_{sd}=N*P_{sd}):7000( [0.17 \quad 0.45]) \rightarrow [1190 \quad 3150]$$

## pruebas de hipótesis

El principal objetivo de la **inferencia** estadística es aproximarse al valor del parámetro $\theta$ de la población ($U$), mediante un estimador $\hat{\theta}$ que viene definido por una muestra aleatoria ($s$).

Las estrategias de estimación vistas hasta ahora son:

  * Estimación puntual: 
  
$$\mu=\frac{\sum_U x_i}{N} \rightarrow \bar{x}=\frac{\sum_s x_i}{n}$$
  
  * Estimación por intervalo de confianza
  
$$IC_{1-\alpha}(\mu): \bar{x}\pm z_{\alpha/2}\sqrt{\frac{\hat{S}^2}{n}}$$

Ahora veremos las pruebas de hipótesis estadísticas, estas pruebas partes de una conjetura nuestra al rededor del parámetro de interés y esta conjetura es verificada mediante la información de la muestra. 

Cuando se elabora una hipótesis estadística se debe plantear 2 elementos; la hipótesis que se plantea (hipótesis nula) y el complemento de esta hipótesis planteada se denomina hipótesis alternativa. Ejemplo

$$H_0: \theta = k$$
$$H_1: \theta \neq k$$
$$H_1: \theta > k$$
$$H_1: \theta < k$$
Ejemplo, se observa a los estudiantes inscritos en la materia de estadística mediante una muestra de 10 estudiantes.  Si la variable de interés es la estatura en centímetros

$$H_0: \mu = 165$$
$$H_1: \mu< 165$$

La manera de verificar la hipótesis planteada pasara por estudiar una muestra aleatoria, sobre la cual se pueda establecer una regla que nos permita decidir si la hipótesis es correcta o no. Normalmente se inicia calculando un **estadístico de prueba** que nos permitirá decidir con base a una regla definida en una **región de aceptación**.

Al momento de tomar una decisión con base al estadístico de prueba y las regiones de aceptación y rechazo empleando la información de la muestra, es posible cometer errores dado el resultado real en $U$. En las pruebas de hipótesis existen dos tipos de errores, el **error de tipo I** y el **error de tipo II**:

  * Error de tipo I: ($\alpha$) también conocido como un falso positivo. Rechazar algo verdadero
  * Error de tipo II: ($\beta$) también conocido como falso negativo. Aceptando algo falso
  
### Pasos para una prueba de hipótesis

  1. Establecer la hipótesis nula ($H_0$) y la hipótesis alternativa ($H_1$, $H_A$). La $H_A$ puede ser de dos o una cola
  2. Definir el nivel de significancia $\alpha$. (el tamaño de la región de rechazo)
  3. Recolectar los datos de la muestra y calcular el estadístico de prueba ($Z$).
  4. Comparar el estadístico de prueba según las regiones críticas, esto es, la región de aceptación y la región de rechazo
    + $Z \in RA \rightarrow \sim RH_0 (AH_0)$
    + $Z \notin RA \rightarrow RH_0$
  5. Calcular el P-valor. "La probabilidad que la hipótesis nula sea verdadera". Tradicionalmente:
    + $P-valor>\alpha \rightarrow \sim RH_0 (AH_0)$
    + $P-valor<\alpha \rightarrow RH_0$
  6. Calcular el intervalo de confianza del parámetro de estudio
  7. Realizar las conclusiones respectivas y analizar los resultados.
  
### Prueba de hipótesis para la media 

Vamos a suponer que los datos de interés se distribuyen como una normal o al menos que el tamaño de muestra ($n$), de la muestra aleatoria para el estadístico de prueba es *grande*. Por lo tanto es posible utilizar el teorema del limite central. Existen dos variaciones de la prueba de hipótesis sobre la media; cuando **se conoce la varianza** y cuando **no se conoce la varianza** de los datos ($\sigma^2$). 

#### Con varianza $\sigma^2$ conocida

  1. Hipótesis
  
$$H_0: \mu=\mu_0$$

$$H_A: \mu \neq \mu_0$$
  2. *Nivel de significancia:* Este es $\alpha$ y el tipo de prueba dado la $H_A$ es bilateral o de dos colas, esto significa que existen dos regiones de rechazo, cada región de tamaño $\alpha/2$
  3. *Estadístico de prueba:* Se cuenta con una muestra aleatoria ($X_1,X_2,\ldots,X_n$) estas son independientes e idénticamente distribuidas. La estadística de prueba es:
  
$$Z_0=\frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}}$$  
Si la hipótesis nula es cierta entonces se puede garantizar que $Z_0\sim N(0,1)$, esto significa que: 

$$E[\bar{x}]=\mu=\mu_0$$
  4. *Regiones de aceptación y rechazo:* dependen del nivel de significancia $\alpha$
  
```{r}
# alpha=0.1 (10%)
curve(dnorm(x),xlim = c(-4,4),main="Significancia al 10%")
abline(v=c(-1.64,1.64),col="red",lty=2)
text(c(-3.5,0,3.5),rep(0.2,3),c("Rechazo","Aceptación","Rechazo"))
# alpha=0.05 (5%)
curve(dnorm(x),xlim = c(-4,4),main="Significancia al 5%")
abline(v=c(-1.96,1.96),col="red",lty=2)
text(c(-3.5,0,3.5),rep(0.2,3),c("Rechazo","Aceptación","Rechazo"))
# alpha=0.01 (1%)
curve(dnorm(x),xlim = c(-4,4),main="Significancia al 1%")
abline(v=c(-2.58,2.58),col="red",lty=2)
text(c(-3.5,0,3.5),rep(0.2,3),c("Rechazo","Aceptación","Rechazo"))
```
  
  * La decisión; Se rechaza la $H_0$ cuando:
  
$$Z_0> Z_{\alpha/2} \quad ó \quad Z_0< -Z_{\alpha/2}$$  

Los valores más usuales para el $Z_{\alpha/2}$ son:

  * al 10% de significancia $Z_{\alpha/2}=Z_{0.05}=1.64$
  * al 5% de significancia $Z_{\alpha/2}=Z_{0.025}=1.96$
  * al 1% de significancia $Z_{\alpha/2}=Z_{0.005}=2.58$
  
> Ejercicio, se tiene un curso de estadística con su evaluación final sobre 100 puntos, se sabe por información pasada que la desviación estándar es alrededor de 10 pts. Se debe probar la hipótesis que el grupo tiene una nota promedio de 65 pts, tomar un nivel de significancia del 5%. Para realizar la prueba se obtuvo una muestra de 20 estudiantes, con las siguientes mediciones:

```{r}
set.seed(905)
x<-round(runif(20,45,75))
x
```

$$H_0: \mu= 65$$
$$H_A: \mu\neq 65$$  
  
$$Z_0=\frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}}=\frac{61.5-65}{\frac{10}{\sqrt{20}}}=-1.565$$
La decisión, si se cumple alguna de las siguientes desigualdades se rechaza la hipótesis nula:

$$-1.565> 1.96 (F) \quad ó \quad -1.565< -1.96 (F)$$

Por lo tanto, no se rechaza la hipótesis nula. De manera gráfica:

```{r}
# alpha=0.05 (5%)
curve(dnorm(x),xlim = c(-4,4),main="Significancia al 5%")
abline(v=c(-1.96,1.96),col="red",lty=2)
text(c(-3.5,0,3.5),rep(0.2,3),c("Rechazo","Aceptación","Rechazo"))
abline(v=-1.565,col="blue",lty=3)
text(x=-1.565,y=0.05,"Z0")
```

##### Para pruebas unilaterales

Se utiliza el mismo estadístico de prueba $Z_0$, lo que se modifica son las regiones críticas.

$$H_A: \mu>\mu_0$$
Se rechaza $H_0$ si:

$$Z_0>Z_{\alpha}$$
En el otro caso:

$$H_A: \mu<\mu_0$$
Se rechaza $H_0$ si:

$$Z_0< -Z_{\alpha}$$
Los valores mas usuales de $Z_\alpha$ para pruebas unilaterales son:

  * 10% $Z_{0.1}=1.28$ 
  * 5% $Z_{0.05}=1.64$
  * 1% $Z_{0.01}=2.33$

```{r}
# "<"
curve(dnorm(x),xlim = c(-4,4),main="Pruebas unilaterales <")
abline(v=c(-1.28,-1.64,-2.33),col="red",lty=2)
text(c(-3.5,2),rep(0.2,2),c("Rechazo","Aceptación"))
text(c(-1.28,-1.64,-2.33),y=0.3,c("10%","5%","1%"),cex=0.8)

# ">"
curve(dnorm(x),xlim = c(-4,4),main="Pruebas unilaterales >")
abline(v=c(1.28,1.64,2.33),col="red",lty=2)
text(c(-2,3.5),rep(0.2,2),c("Aceptación","Rechazo"))
text((-1)*c(-1.28,-1.64,-2.33),y=0.3,c("10%","5%","1%"),cex=0.8)
```

#### Con varianza desconocida

Si el tamaño de muestra es mayor a 30, todo lo visto anteriormente se mantiene, el único cambio se da en el estadístico de prueba, donde en lugar de $\sigma$ se toma la variabilidad muestral ($\hat{S}$). Es decir:

$$\sigma^2=\frac{\sum_U (x_i-\mu)^2}{N}$$

$$\hat{S}^2=\frac{\sum_s (x_i-\bar{x})^2}{n-1}$$

Esto implica que:

$$Z_0=\frac{\bar{x}-\mu_0}{\frac{\hat{S}}{\sqrt{n}}}$$

Si la muestra no es mayor a 30, podemos hacer un supuesto de normalidad y la aproximación para las regiones críticas se la trabaja con la distribución $t-student$

```{r}
curve(dnorm(x),xlim=c(-4,4),lwd=2)
for(i in 1:30){
curve(dt(x,i),xlim=c(-4,4),lty=2,col="red",add=T)
}
```

Hasta ahora se tienen 3 casos para la prueba de hipótesis sobre la media.

$$H_0: \mu=\mu_0$$

  1. Cuando la varianza es conocida, se utiliza la distribución normal y el estadístico de prueba es:
  
$$Z_0=\frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}}$$
$$Z_0\sim N(0,1)$$
Para: 

$$H_A: \mu \neq\mu_0$$
Se rechaza la $H_0$ cuando:

$$Z_0 < -Z_{\alpha/2}\quad  ó \quad Z_0 > Z_{\alpha/2}$$

$$H_A: \mu <\mu_0$$
Se rechaza la $H_0$ cuando:

$$Z_0 < -Z_{\alpha}$$

$$H_A: \mu >\mu_0$$
Se rechaza la $H_0$ cuando:

$$Z_0 > Z_{\alpha}$$

  2. Cuando la varianza es desconocida y la muestra es mayor a 30, se utiliza la distribución normal y el estadístico de prueba es:

$$Z_0=\frac{\bar{x}-\mu_0}{\frac{\hat{S}}{\sqrt{n}}}$$

$$Z_0\sim N(0,1)$$

Para: 

$$H_A: \mu \neq\mu_0$$
Se rechaza la $H_0$ cuando:

$$Z_0 < -Z_{\alpha/2}\quad  ó \quad Z_0 > Z_{\alpha/2}$$

$$H_A: \mu <\mu_0$$
Se rechaza la $H_0$ cuando:

$$Z_0 < -Z_{\alpha}$$

$$H_A: \mu >\mu_0$$
Se rechaza la $H_0$ cuando:

$$Z_0 > Z_{\alpha}$$


  3. Cuando la varianza es desconocida y la muestra es menor o igual a 30, se utiliza la distribución t-student y el estadístico de prueba es:
  
$$t_0=\frac{\bar{x}-\mu_0}{\frac{\hat{S}}{\sqrt{n}}}$$  

$$t_0\sim t(v=n-1)$$

Para: 

$$H_A: \mu \neq\mu_0$$
Se rechaza la $H_0$ cuando:

$$t_0 < -t_{\alpha/2,n-1}\quad  ó \quad t_0 > t_{\alpha/2,n-1}$$

$$H_A: \mu <\mu_0$$
Se rechaza la $H_0$ cuando:

$$t_0 < -t_{\alpha,n-1}$$

$$H_A: \mu >\mu_0$$
Se rechaza la $H_0$ cuando:

$$t_0 > t_{\alpha,n-1}$$

Ejemplo, Se tiene el peso en kilogramos de una muestra aleatoria de tamaño 5 de un determinado animal, estos datos son: 4.5, 6.7, 5.0, 4.0 y 6.1. Se piensa que estos animales tienen problemas de nutrición y se busca verificar esto mediante la muestra recolectada. Se acepta que existen problemas de nutrición si el peso es inferior a 4.2 kg. Realice la prueba de hipótesis correspondiente para verificar esto. 

Solución,

$$H_0: \mu=4.2 \quad ; \quad H_A: \mu<4.2$$

$$t_0=\frac{\bar{x}-\mu_0}{\frac{\hat{S}}{\sqrt{n}}}=\frac{5.26-4.2}{\frac{1.12}{\sqrt{5}}}=2.12$$

(Vamos a utilizar un nivel de significancia del 5%) Se rechaza la $H_0$ cuando la siguiente desigualdad se cumpla:


$$2.12 < -t_{0.05,4}=-2.1318$$

Por lo tanto, como no se cumple la desigualdad, se concluye que no existe evidencia estadística suficiente para rechazar la hipótesis nula. Esto implica que posiblemente la población de animales estudiados no tengan problemas de nutrición. 

Ejercicio, Se considera que un determinado fruto esta maduro cuando su árbol supera la altura de 175 centímetros, para verificar si ya se puede cosechar la fruta se toma una muestra aleatoria de 7 árboles, teniendo los siguientes resultados:
140, 200, 178, 167, 170, 180, 192. ¿Será que ya se puede realizar la cosecha?

Solución,

$$H_0: \mu=175 \quad ; \quad H_A: \mu>175$$

$$t_0=\frac{\bar{x}-\mu_0}{\frac{\hat{S}}{\sqrt{n}}}=\frac{175.29-175}{\frac{19.41}{\sqrt{7}}}=0.0395$$

Se rechaza la $H_0$ cuando se cumple la siguiente desigualdad:

$$t_0 > t_{0.05,6}$$
Suponiendo un $\alpha=0.05$ (5%)

$$0.0395 > 1.9432 (F)$$
Por lo tanto, como la desigualdad no se cumple; no es posible rechazar la hipótesis nula, esto implica que no se recomienda iniciar con la cosecha.

### Tamaño de muestra a partir del margen de error

Recordar el intervalo de confianza de la media:

$$\bar{x} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}\quad ; \quad \bar{x} \pm \epsilon$$

Imaginemos que queremos controlar el ancho del intervalo de confianza, a ese ancho lo vamos a denominar margen de error ($\epsilon$), entonces:

$$\epsilon=z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$$

Ahora, es posible delimitar a priori el margen de error, el nivel de confiabilidad y aproximar $\sigma$ con base a un estudio pasado o una prueba piloto. De esta forma es posible tener una formula para el tamaño de muestra $n$, en función de $\epsilon$, $z_{\alpha/2}$ y $\sigma$. Esta es:

$$n=\left(\frac{z_{\alpha/2}* \sigma}{\epsilon}\right)^2\approx \left(\frac{z_{\alpha/2}* \hat{\sigma}}{\epsilon}\right)^2$$

Ejemplo, para el caso de los árboles y la cosecha, calcular el tamaño de muestra necesario si se fija un margen de error de 5 cm, un nivel de confiabilidad del 95%, usar como aproximación de $\sigma$ el dato de los 7 árboles. 

$$n= \left(\frac{z_{\alpha/2}* \hat{\sigma}}{\epsilon}\right)^2=\left(\frac{1.96* 19.41}{5}\right)^2=57.89\approx58$$

### Tamaño de muestra a partir de los errores de tipo I y II

Cuando se trabaja con tamaños de muestra basados en los errores de tipo I y II, se debe predefinir 3 aspectos:

  * El tamaño del error de tipo I: $\alpha$, $0.01, 0.05, 0.1$
  * El tamaño del error de tipo II: $\beta$, $0.1, 0.2$
  * Efecto de tamaño: 

$$\delta=|\mu_0-\mu_A|$$

$$n=\left[\frac{\hat{\sigma} *(z_{\alpha}+z_\beta)}{\delta}\right]^2=\frac{\hat{\sigma}^2 *(z_{\alpha}+z_\beta)^2}{\delta^2}$$  
Los valores más comunes:

  * $z_{\alpha=0.05}=1.64$
  * $z_{\alpha=0.01}=2.33$
  * $z_{\alpha=0.1}=1.28$
  * $z_{\beta=0.1}=1.28$
  * $z_{\beta=0.2}=0.84$

> Ejemplo

¿Cuán grande debe ser el tamaño de muestra si de define un nivel de significancia del 5%, un error de tipo II del 10%, debiendo detectar una diferencia al promedio de al menos 1. Teniendo una varianza de 1.57.

Solución, $\delta=1$

$$n=\frac{\hat{\sigma}^2 *(z_{\alpha}+z_\beta)^2}{\delta^2}=\frac{1.57 *(1.64+1.28)^2}{1}=13.38\approx 14$$

> Ejercicio

Para el ejemplo de los árboles, se sabe que $\hat{\sigma}=19.41$, si se quiere obtener el tamaño de muestra necesario tomando en cuenta una distancia mínima de 5 centímetros. Calcular el tamaño de muestra necesario, tomar un $\alpha$ del 5% y un $\beta$ del 20%.

$$n=\left[\frac{\hat{\sigma} *(z_{\alpha}+z_\beta)}{\delta}\right]^2=\left[\frac{19.41 *(1.64+0.84)}{5}\right]^2=92.69\approx 93$$

  * $z_{\alpha=0.05}=1.64$
  * $z_{\alpha=0.01}=2.33$
  * $z_{\alpha=0.1}=1.28$
  * $z_{\beta=0.1}=1.28$
  * $z_{\beta=0.2}=0.84$

$$n=\left[\frac{(z_{\alpha}+z_\beta)}{\frac{\delta}{\hat{\sigma}}}\right]^2$$

$$EMD=\frac{\delta}{\hat{\sigma}}=\frac{|\mu_0-\mu_A|}{\hat{\sigma}}$$
Se conoce como el efecto mínimo detectable, que mide la diferencia entre en términos de desviaciones estándar. Existen valores sugeridos para este EMD, varían de 0.15 a 0.25.
